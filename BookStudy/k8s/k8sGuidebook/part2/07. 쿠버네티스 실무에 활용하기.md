# 목차
- 2파트 쿠버네티스 실무에 활용하기 (6장)
  - 7.1 파드와 컨테이너의 통신
  - 7.2 초기화 컨테이너를 이용한 애플리케이션 시작
  - 7.3 어댑터 컨테이너를 이용한 일관성 있는 애플리케이션 관리
  - 7.4 외부와의 통신을 추상화하기: 앰배서더 컨테이너
  - 7.5 파드 환경 이해하기
  - 7.6 연습 문제

# 서론
파드 하나에 여러 개 컨테이너를 실행할 수 있다. 멀티 컨테이너 파드를 사용해본다.  
대게 앱 컨테이너와 함께 헬퍼 컨테이너가 추가되는 형태다.  
  
한 파드 안에서 여러 컨테이너는 동일한 가상 환경을 공유한다.  
따라서 컨테이너의 동작을 다른 컨테이너가 반응하여 연결된 동작을 할 수도 있다.  

# 7.1 파드와 컨테이너의 통신
파드 안에 컨테이너들은 네트워크 및 파일 시스템을 공유한다. -> 모든 컨테이너가 같은 IP 주소 (파드 IP)를 갖는다.  
각 컨테이너는 별도 환경 변수와 자신만의 프로세스, 기술 스택을 갖는다.  
즉 별개의 이미지를 사용 할 수 있는 독립된 단위다.  
  
파드는 노드상에서 동작하는 하나의 단위다. 파드에 속한 컨테이너는 모두 같은 노드에서 동작한다.  
파드 안 컨테이너 간에는 localhost 주소를 사용하고, 별개 파일 시스템을 갖지만,  
볼륨은 파드 수준에서 정의되며 같은 볼륨을 마운트하여 컨테이너끼리 데이터 공유한다.  
  
네트워크와 디스크 공유만으로 많은 일들을 할 수 있다. 뒤에서 살펴보자.  
  
- 예제 7-1 
  - 디플로이먼트에 포함된 멀티 컨테이너 파드 정의
  - 같은 이미지 사용 두 컨테이너 정의
  - 파드에서 정의된 공디렉터리 볼륨이 마운트
  ```yaml
  spec:
    containers:
      - name: sleep
        image: kiamol/ch-sleep
        volumeMounts:
          - name: data
            mountPath: /data-rw # 볼륨을 쓰기 기능으로 마운트
      - name: file-reader # 컨테이너는 각기 다른 이름을 갖는다.
        image: kiamol/ch03-sleep # 같은 이미지도 사용 가능하다
        volumeMounts:
          - name: data
            mountPath: /data-ro
            readOnly: true # 다른 컨테이너와 다르게 읽기 전용 볼륨 마운트
    volumes:
      - name: data # 같은 볼륨을 여러 컨테이너에 마운트 가능
        emptyDir: {}
  ```
- 실습 
  - 두 컨테이너 파드 정의 배치
  - cd 07
  - kubectl apply -f sleep/sleep-with-file-reader.yaml
  - kubectl get pod -l app=sleep -o wide
  - kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.containerStatuses[*].name}'
    - 컨테이너 이름 출력
  - kubectl logs -l app=sleep
  
파드는 하나의 IP를 갖고 두 개의 컨테이너가 같은 노드에서 실행되고 있다.  
그러나 하나의 단위인 파드로 로그 출력은 할 수 없다. 즉 컨테이너 중 하나를 지정해서 로그 출력해야한다.  
- 실습
  - 한 컨테이너는 쓰기 기능, 다른 컨테이너는 읽기 전용 볼륨 마운트로 됐다.
  - kubectl exec deploy/sleep -c sleep -- sh -c 'echo ${HOSTNAME} > /data-rw/hostname.txt'
    - sleep -> 공유 볼륨으로 파일 기록
  - kubectl exec deploy/sleep -c sleep -- cat /data-rw/hostname.txt
    - sleep -> 기록한 파일 읽음
  - kubectl exec deploy/sleep -c file-reader -- cat /data-ro/hostname.txt
    - file-reader -> 기록한 파일 읽음
  - kubectl exec deploy/sleep -c file-reader -- sh -c 'echo more >> /data-ro/hostname.txt'
    - file-reader -> 쓰기 권한 X - 오류 발생
  
파드 환경의 두 번 째 공유 요소는 네트워크다.  
컨테이너는 개별 고유 포트를 쓰는 형태로 공유된다.  
- 예제 7-2
  ```yaml 
  spec:
    containers:
      - name: sleep
        image: kiamol/ch03-sleep # 예제 7-1과 동일 컨테이너 정의
      - name: server
        image: kiamol/ch03-sleep # 두 번째 컨테이너 정의 변경
        command: ['sh', '-, "while true; do echo -e 'HTTP/1.1 ..."]
        ports:
          - containerPort: 8080 # 앱 사용 포트를 기록
  ```
  - 800 포트 HTTP 엔드 포인트 제공 서버 컨테이너 같이 실행
  - 두 컨테이너는 네트워크 주소 공유 -> sleep, server 서로 접근 가능
- 실습
  - 7-2 정의 업데이트
  - 서버 컨테이너 접근 가능한지 체크
  - kubectl apply -f sleep/sleep-with-server.yaml
  - kubectl get pods -l app=sleep
  - kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.containerStatuses[*].name}'
    - 파드 속 컨테이너 이름 확인
  - kubectl exec deploy/sleep -c sleep -- wget -q -O - localhost:8080
    - sleep 컨테이너에서 서버 컨테이너로 통신
  - kubectl logs -l app=sleep -c server
  
이런 현상은 파드에 국한되지 않는다.  
파드 속 컨테이너가 어떤 포트를 주시하고 있다면, 다른 파드가 이 포트로 컨테이너에 접근 가능하다.  
트래픽을 파드의 특정 포트로 전달하면, 이 포트를 주시한 컨테이너가 전달받는다.  
- 실습
  - 파드 포트 개방 후 외부에서 http 서버 컨테이너 접근 가능 여부 체크
  - kubectl expose -f sleep/sleep-with-server.yaml --type LoadBalancer --port 8020 --target-port 8080
    - 서버 컨테이너 포트를 가리키는 서비스 생성
  - kubectl get svc sleep -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8020'
    - 서비스 URL 출력
  - 웹 브라우저 출력 URL 접근
  - kubectl logs -l app=sleep -c server
  
웹 서버, API 두 컨테이너를 한 파드에 몰아넣으면 안 된다.  
파드는 앱을 구성하는 한 단위이고, 단일 컴포넌트에 대응해야 한다.  
앱 컨테이너를 지원하는 컨테이너를 멀티 컨테이너로 만들 순 있지만 서로 다른 앱으로 파드를 구성하면 안 된다.  
서로 다른 앱을 한 파드에 넣는 경우 스케일링 또는 독립적 업데이트가 애매해진다.  

# 7.2 초기화 컨테이너를 이용한 애플리케이션 시작
앱 컨테이너보다 추가 컨테이너를 먼저 실행해 앱 실행 준비를 하는 경우 추가 컨테이너를 '초기화 컨테이너'라 한다.  
초기화 컴포넌트는 순서대로 실행-목표 달성을 거치며 모두 실행 된 후 앱 컨테이너나 사이드카 컨테이너를 실행한다.  
  
초기화 컨테이너의 역할은 앱 환경에 필요한 데이터를 세팅하는 것이다.  
- 예제 7-3
  ```yaml
  spec: # 디플로이먼트의 template 필드에 정의된 파드
    initContainers: # 초기화 컨테이너는 배열 형태로 기재
      - name: init-html # 나열된 순서로 실행
        image: kiamol/ch03-sleep
        command: ['sh', '-c', "echo '<!DOCTYPE html...' > /data/index.html"]
        volumeMounts:
          - name: data
            mountPath: /data # 초기화 컨테이너는 파드의 볼륨 마운트 할 수 있다.
  ```
- 실습 
  - 초기화 컨테이너 동작 과정 관찰
  - kubectl apply -f sleep/sleep-with-html-server.yaml
  - kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.containerStatuses[*].name}'
  - kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.initContainerStatuses[*].name}'
  - kubectl logs -l app=sleep -c init-html
  - kubectl exec deploy/sleep -c server -- ls -l /data-ro
    - 사이드카 컨테이너에서 초기화 컨테이너 생성 파일 접근 가능 여부 체크
  
초기화 컨테이너는 실행된 후 종료되고, 컨테이너 종료 후에도 로그 확인 가능하다.  
- 실습
  - 특정 시간마다 타임스탬프를 파일에 기록하는 앱
  - 구식 방법으로 설정 됌 -> 배운 앱 설정 적용 X
  - kubectl apply -f timecheck/timecheck.yaml
    - 단일 설정 파일만 사용하는 앱 실행
  - kubectl logs -l app=timecheck
  - kubectl exec deploy/timecheck -- cat /logs/timecheck.log
  - kubectl exec deploy/timecheck -- cat /config/appsettings.json
  
파드에 컨테이너 추가로 제한됐던 로그를 확인 가능해졌다.  
즉 앱과 K8s 버전 호환이 되지 않아 해당 채널의 로그를 탐지할 수 없지만,  
컨테이너 파일 시스템 로그 파일로 로그를 대체 출력 가능하다.  
  
- 예제 7-4
  - 설정 파일 구성하는 초기화 컨테이너
  ```yaml
  spec:
    initContainers:
      - name: init-config
        image: kiamol/ch03-sleep # 이미지에 jq 명령이 존재
        command: ['sh', '-c', "cat /config-in/appsettings.json | jq --arg APP_ENV \"APP_ENVIRONMENT\" '.Application.Environment=$APP_ENV' > /config-out/appsettings.json]
        env:
          - name: APP_ENVIRONMENT # 모든 컨테이너는 각자 환경 변수를 갖는다.
            value: TEST # 이 환경 변수는 파드 안에서 공유되지 않는다.
        volumeMounts:
          - name: config-map # 컨피그맵 읽어들이는 볼륨
            mountPath: /config-in
          - name: config-dir
            mountPath: /config-out # 구성된 설정 파일을 기록할 공디렉터리 볼륨
  ```
  - 앱 컨테이너가 컨피그맵, 환경 변수를 직접 사용하지 않아도 된다.
  
- 실습
  - timecheck 앱 여러 출처 설정 값 사용 정의
  - kubectl apply -f timecheck/timecheck-configMap.yaml -f timecheck/timecheck-with-config.yaml
    - 컨피그맵 배치, 디플로이먼트 정의
  - kubectl wait --for=condition=ContainersReady pod -l app=timecheck,version=v2
  - kubectl exec deploy/timecheck -- cat /logs/timecheck.log
  - kubectl exec deploy/timecheck -- cat /config/appsettings.json
  
# 7.3 어댑터 컨테이너를 이용한 일관성 있는 애플리케이션 관리
사이드카 컨테이너는 초기화 컨테이너만으로 레거시 앱을 현대화할 수 없는 경우 유용하다.  
앱과 컨테이너 플랫폼 사이를 중재하는 어댑터 역할을 사이드카 컨테이너를 통해 할 수 있다.  
로그가 그 중 대표적인 예이다.  
  
도커와 K8s는 표준 출력으로 컨테이너의 로그를 수집한다.  
레거시 앱은 표준 출력 대신 파일에 직접 로그를 남기거나 컨테이너 로그가 수집될 수 없는 채널을 이용해 로그를 남겼다.  
간단한 사이드카 컨테이너를 통해 문제를 해결 할 수 있다.  
  
- 예제 7-5
  - 컨테이너 로그 수집을 도와주는 사이드카 컨테이너
  ```yaml
  containers:
    - name: timecheck
      image: kiamol/ch07-timecheck
      volumeMounts:
        - name: logs-dir # 이 앱은 공 디렉터리 볼륨의 파일에 로그 기록
          mountPath: /logs
    # 컨피그맵 마운트 정의 생략
    - name: logger
      image: kiamol/ch03-sleep # 사이드카 컨테이너는 로그 파일 주시
      command: ['sh', '-c', 'tail -f /logs-ro/timecheck.log']
      volumeMonts:
        - name: logs-dir
          mountPath: /logs-ro # 앱과 같은 볼륨 마운트
          readOnly: true
  ```
  - 사이드카 컨테이너는 로그가 출력되는 볼륨을 마운트하고 로그 파일 내용을 tail 명령으로 표준 출력 스트림에 출력한다.
  - 이런 방식을 통해 앱 로그 구현과 K8s 로그 수집 방식을 연결하는 중재자 역할을 한다.
- 실습
  - 위 예제 정의 후 앱 로그 확인
  - kubectl apply -f timecheck/timecheck-with-logging.yaml
  - kubectl wait --for=condition=ContainersReady pod -l app=timecheck,version=v3
  - kubectl get pods -l app=timecheck
  - kubectl get pod -l app=timecheck -o jsonpath='{.items[0].status.containerStatuses[*].name}'
  - kubectl logs -l app=timecheck -c logger
  
로그를 다시 읽어 표준 출력으로 바꾸는 것은 약간의 시차와 일부 디스크 용량이 낭비된다.  
그러나 애플리케이션 자체를 바꾸지 않고, 호환되게 만들어 로그 수집 할 수 있게 됐다.  
  
앱에 따라 커스터마이징된 정보 수집, 헬스 체크, 성능 지표 수집 기능을 갖춘 이미지를 사용 할 수 도 있다.  
- 예제 7-6
  - 사이드카 컨테이너로 앱 확장하기
  ```yaml
  containers: # 앱 컨테이너, 로깅 컨테이너는 그대로다
    - name: timecheck
    # 중략
    - name: logger
    # 중략
    - name: healthz # 추가되는 사이드카 컨테이너는 헬스체크 API 제공
      image: kiamol/ch03-sleep # 이 응답은 하드코딩된 응답이다
      command: ['sh', '-c', 'while true; do echo -e 'HTTP/1.1 200 OK\nContent-Type: application/json\nContent-Length: 17\n\n{\"status\": \"OK\"}' | nc -l -p 8080; done"]
        ports:
          - containerPort: 8080 # 파드 포트 8080
    - name: metrics # 성능 지표 사이드카 API 제공
      image: kiamol/ch03-sleep
      command: ['sh', '-c', 'while true; do echo -e 'HTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 104\n\n# Help timechecks_total The total number timechecks.\n# TYPE timechecks_total counter\ntimechecks 6' | nc -l -p 8081; done"]
        ports:
          - containerPort: 8081
  ```
- 실습
  - 업데이트 적용, 헬스체크 API, 성능 지표 API 확인
  - kubectl apply -f timecheck/timecheck-good-citizen.yaml
  - kubectl wait --for=condition=ContainersReady pod -l app=timecheck,version=v4
  - kubectl get pod -l app=timecheck -o jsonpath='{.items[0].status.containerStatuses[*].name}'
  - kubectl exec deploy/sleep -c sleep -- wget -q -O - http://timecheck:8080
  - kubectl exec deploy/sleep -c sleep -- wget -q -O - http://timecheck:8081
  
어댑터 역할의 사이드카 컨테이너는 오버헤드로 작용한다.  
즉 파드 업데이트 시간도 길어지고, 계산과 메모리 자원을 소모한다.  
  
앱 네트워크 통신을 자세하게 제어하고 싶다면 사이드카 컨테이너를 사용하는 방법도 있다.  

# 7.4 외부와의 통신을 추상화하기: 앰배서더 컨테이너
앰버서더 컨테이너는 앱과 외부 통신을 제어, 단순화 역할을 수행한다. (성능 향상, 신뢰성, 보안 강화)  
앱 주소로 네트워크 요청시 앰배서더 컨테이너가 받아 처리하는 형태다.  
DB 앰버서더 컨테이너의 경우 마스터 서버에 update 쿼리, 레플리카에 read로 보내도록 설정 할 수 있다.  
  
앰버서더 컨테이너로 추상화하여 활용도를 높일 수 있다.  
서비스 디스커버리, 로드밸런싱, 연결 재시도, 비보안 채널 암호화 등 역할에 맞게 설정하면 된다.  
- 실습
  - 무작위 숫자 생성 앱 실행
  - 웹 앱 컨테이너에서 아무 주소나 통신 가능한지 체크
  - kubectl apply -f numbers/
    - 앱 및 서비스 배치
  - kubectl get svc numbers-web -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8090'
  - 앱 접근
  - kubectl exec deploy/numbers-web -c web -- wget -q -O - http://timecheck:8080
- 예제
  - 프록시 엠버서더 컨테이너를 프록시로 사용 할 경우 추가적인 기능
  ```yaml
  containers:
    - name: web
      image: kiamol/ch03-numbers-web
      env:
        - name: http_proxy # 프록시 사용 설정시
          value: http://localhost:1000 # 모든 트래픽이 앰버서더 컨테이너를 거친다.
        - name: RngApi__Url
          value: http://localhost/api # API 접근 localhost 주소
    - name: proxy
      image: kiamol/ch07-simple-proxy # 간단 HTTP 프록시
        env:
          - name: Proxy__Port # 앱 네트워크 요청을 라우팅
            value: "1000" # 설정된 URL 매핑에 따라 라우팅
          - name: Proxy__Request_UriMap__Source
            value: http://localhost/api
          - name: Proxy__Request__UriMap_Target
            value: http://numbers-api/sixyed/kiamol/master/ch03/numbers/rng
  ```
  - 프록시 컨테이너를 거쳐 모든 네트워크 통신 수행
- 실습
  - 무작위 숫자 앱 업데이트 후 접근 가능 주소 제한 체크
  - kubectl apply -f numbers/update/web-with-proxy.yaml
  - 웹 앱 새로고침
  - kubectl logs -l app=numbers-web -c proxy
  - kubectl exec deploy/numbers-web -c web -- wget -q -O - http://timecheck:8080
  - kubectl logs -l app=numbers-web -c proxy
  
웹 앱과 API의 느슨한 구조를 유지할 수 있다.  
앰버서더 컨테이너 역할이 프록시만 있는건 아니다.  
네트워크 전송 계층에 넣어 트래픽 처리를 할 수도 있다.  
데이터베이스 수정, 읽기를 구분할 수도 있다.  

# 7.5 파드 환경 이해하기
파드는 하나 이상의 컨테이너를 감싸는 경계, 컨테이너는 하나의 프로세스를 감싸는 경계다.  
파드는 컴퓨팅의 기본 단위라는 것을 기억하자.  
파드 안 모든 컨테이너가 준비 돼야 파드가 준비 상태가 된다.  
- 실습
  - 초기화 컨테이너 실패시 앱 고장
  - kubectl apply -f numbers/update/web-v2-broken-init-container.yaml
  - kubectl get po -l app=numbers-web,version=v2
  - kubectl logs -l app=numbers-web,version=v2 -c init-version
  - kubectl get deploy numbers-web
  - kubectl get rs -l app=numbers-web
  
초기화 컨테이너 실패로 앱 업데이트가 되지 않는다.  
디플로이먼트는 멀티 컨테이너 파드의 초기화 컨테이너 정상 종료 후 파드 안 모든 컨테이너가 Running 상태가 되기를 기다린다.  
- 재시작 조건
  - 파드 대체시 초기화 컨테이너가 존재한다면 새 파드는 초기화 컨테이너를 모두 실행, 초기화 로직은 반복적 실행이 가능해야 한다.
  - 초기화 컨테이너 이미지 변경시 파드 자체 재시작, 초기화 컨테이너 재실행되고 앱 컨테이너 모두 교체된다.
  - 파드 정의에서 앱 컨테이너 이미지 변경 -> 앱 컨테이너 대체, 초기화 컨테이너는 재시작 안 한다.
  - 앱 컨테이너 종료 -> 파드가 앱 재생성, 대체 컨테이너 준비 전 서비스에서 트래픽을 받지 못한다.
  
아직 파드 내 환경의 컴퓨팅 계층을 다루지 않았다.  
파드 속 컨테이너는 네트워크 주소, 파일 시스템 일부를 공유할 수 있지만, 프로세스간 접근은 할 수 없다.  
그러나 사이드카 컨테이너에서 앱 프로세스에 접근해야 할 때가 있다.  
파드 정의에 'shareProcessNamespace: true' 추가를 통해 접근시킬 수 있다.  
- 실습
  - 컨테이너가 컴퓨팅 공간 공유하도록 업데이트 (sleep)
  - 다른 컨테이너 프로세스 접근 가능 여부 체크
  - kubectl exec deploy/sleep -c sleep -- ps
  - kubectl apply -f sleep/sleep-with-server-shared.yaml
  - kubectl wait --for=condition=ContainersReady pod -l app=sleep,version=shared
  - kubectl exec deploy/sleep -c sleep -- ps
  
nginx, Mysql을 한 파드에 실행하는 것은 금물이다.  
- 실습
  - 해당 장 레이블 일치 모든 리소스 제거
  - kubectl delete all -l kiamol=ch07

# 7.6 연습 문제
- ch07/lab/pi yaml 실행 -> 오류 있음 문제 해결 필요
- 해답 ch07/lab/README.md 참조


# 해당 파트 사용 명령어 모음
- kubectl apply -f sleep/sleep-with-file-reader.yaml
- kubectl get pod -l app=sleep -o wide
- kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.containerStatuses[*].name}'
- kubectl logs -l app=sleep
- kubectl exec deploy/sleep -c sleep -- sh -c 'echo ${HOSTNAME} > /data-rw/hostname.txt'
- kubectl exec deploy/sleep -c sleep -- cat /data-rw/hostname.txt
- kubectl exec deploy/sleep -c file-reader -- cat /data-ro/hostname.txt
- kubectl exec deploy/sleep -c file-reader -- sh -c 'echo more >> /data-ro/hostname.txt'
- kubectl apply -f sleep/sleep-with-server.yaml
- kubectl get pods -l app=sleep
- kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.containerStatuses[*].name}'
- kubectl exec deploy/sleep -c sleep -- wget -q -O - localhost:8080
- kubectl logs -l app=sleep -c server
- kubectl expose -f sleep/sleep-with-server.yaml --type LoadBalancer --port 8020 --target-port 8080
- kubectl get svc sleep -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8020'
- kubectl logs -l app=sleep -c server
- kubectl apply -f sleep/sleep-with-html-server.yaml
- kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.containerStatuses[*].name}'
- kubectl get pod -l app=sleep -o jsonpath='{.items[0].status.initContainerStatuses[*].name}'
- kubectl logs -l app=sleep -c init-html
- kubectl exec deploy/sleep -c server -- ls -l /data-ro
- kubectl logs -l app=timecheck
- kubectl exec deploy/timecheck -- cat /logs/timecheck.log
- kubectl exec deploy/timecheck -- cat /config/appsettings.json
- kubectl apply -f timecheck/timecheck-configMap.yaml -f timecheck/timecheck-with-config.yaml
- kubectl wait --for=condition=ContainersReady pod -l app=timecheck,version=v2
- kubectl exec deploy/timecheck -- cat /logs/timecheck.log
- kubectl exec deploy/timecheck -- cat /config/appsettings.json
- kubectl apply -f timecheck/timecheck-with-logging.yaml
- kubectl wait --for=condition=ContainersReady pod -l app=timecheck,version=v3
- kubectl get pods -l app=timecheck
- kubectl get pod -l app=timecheck -o jsonpath='{.items[0].status.containerStatuses[*].name}'
- kubectl logs -l app=timecheck -c logger
- kubectl apply -f timecheck/timecheck-good-citizen.yaml
- kubectl wait --for=condition=ContainersReady pod -l app=timecheck,version=v4
- kubectl get pod -l app=timecheck -o jsonpath='{.items[0].status.containerStatuses[*].name}'
- kubectl exec deploy/sleep -c sleep -- wget -q -O - http://timecheck:8080
- kubectl exec deploy/sleep -c sleep -- wget -q -O - http://timecheck:8081
- kubectl apply -f numbers/
- kubectl get svc numbers-web -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8090'
- kubectl exec deploy/numbers-web -c web -- wget -q -O - http://timecheck:8080
- kubectl apply -f numbers/update/web-with-proxy.yaml
- kubectl logs -l app=numbers-web -c proxy
- kubectl exec deploy/numbers-web -c web -- wget -q -O - http://timecheck:8080
- kubectl logs -l app=numbers-web -c proxy
- kubectl apply -f numbers/update/web-v2-broken-init-container.yaml
- kubectl get po -l app=numbers-web,version=v2
- kubectl logs -l app=numbers-web,version=v2 -c init-version
- kubectl get deploy numbers-web
- kubectl get rs -l app=numbers-web
- kubectl exec deploy/sleep -c sleep -- ps
- kubectl apply -f sleep/sleep-with-server-shared.yaml
- kubectl wait --for=condition=ContainersReady pod -l app=sleep,version=shared
- kubectl exec deploy/sleep -c sleep -- ps
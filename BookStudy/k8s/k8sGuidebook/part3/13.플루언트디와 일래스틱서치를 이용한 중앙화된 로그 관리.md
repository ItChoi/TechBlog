# 목차
- 3파트 운영 환경으로 가자
    - 13.1 쿠버네티스의 로그 관리 
    - 13.2 플루언트디를 이용한 로그 파일 수집
    - 13.3 수집된 로그를 일래스틱서치에 저장하기
    - 13.4 로그 파싱 및 필터링하기
    - 13.5 쿠버네티스에 적용할 수 있는 그 외 로그 모델

---

# 서론
앱에서 발생하는 로그 중 **개발자에게 유용한 로그**는 별로 없다.  
앱 실행 파드 수가 급격히 늘어나면서, 로그 관리가 복잡해지고, 관리 필요성이 중요하다.  
  
보통 로그 프레임워크를 사용한다.  
1. 중앙 저장소
   - 컨테이너 발생 로그 수집
   - 색인
   - 필터링
   - 검색
  
가장 널리 쓰이는 플루언트디, 일래스틱서치 활용해 로그 프레임워크를 구성하는 방법을 살펴보자.  
- 플루언트디
  - 컨테이너 로그 수집 역할
  - K8s 통합이 쉽다.
- 일래스틱서치
  - 로그 저장 역할
  - 클러스터 내 파드 또는 외부 서비스 형태로 사용
  
- 전제사항
  - 앱 로그는 **컨테이너 표준 출력 스트림**으로 출력되어야 한다. -> K8s가 로그 탐지 가능 방식
  - 컨테이너 표준 출력 스트림 두 가지 방식
    1. 표준 출력 스트림 곧바로 출력
       - 컨테이너에서 실행된 모든 로그는 컨테이너 표준 출력(stdout), 표준 에러(stderr) 스트림으로 곧바로 출력된다.
       - K8s의 각 컨테이너 로그는 파드의 노드 파일 시스템에 저장 (/var/log/containers)
         - 로그 직접 확인: kubectl logs <podName> -c <containerName>
       - 간단 구조 -> 앱 출력 로그 -> 클러스터 로그 수집 시스템 전송
       - 추가 설정 x, 바료 사용 가능, 빠른 로그 확인 가능
       - 복잡 로그 처리, 다양한 수집 전략 적용 제한적
    2. 로그 수집용 사이드카 컨테이너를 이용해 로그 전달 (K8s 로그 모델, 도커 로그 모델과 차이가 많다. - 부록 D참고)
       - 사이드카 컨테이너: 파드 내에 보조 컨테이너로 로그 수집 등 부가 기능 제공
       - 주 컨테이너가 기록하는 로그 파일 또는 경로를 사이드카 컨테이너가 읽어 외부 로그 수집 시스템 전송
         - 로그 수집 도구 -> 외부 로그 시스템
           - 로그 수집 도구: fluent bit, fluentd, filebeat, ...
           - 외부 로그 시스템: Elasticsearch, Loki, Splunk, ...
       - 로그 수집 전략 세분화 가능
       - 로그 처리, 수집 독립 관리 -> 컨테이너 부하 및 관리 용이
       - 사이드카 컨테이너 -> 추가 리소스 소비 증가
       - 설정 복잡 -> 로그 파일 경로, 수집 로직 등
  
# 13.1 쿠버네티스의 로그 관리 
K8s 로그 관리는 간단하다.  
컨테이너 런타임이 로그 수집 후 실행 중인 컨테이너 노드에 파일 형태로 저장한다.  
더 **복잡한 처리 과정 필요시 별도 로그 관리 시스템**을 배치해야 한다. (그림 참고)  
  
컨테이너 출력 로그를 노드에 그대로 저장한다.  
로그 파일 이름: 네임스페이스, 파드, 컨테이너 이름  
  
**로그 수집기도 파드 형태로 실행**되므로, K8s API를 통해 자세한 정보를 얻을 수 있다.  
플루언트디는 로그를 수집하고 가공하며 파드의 레이블, 이미지 태그 정보를 메타데이터에 추가함으로써 **로그 필터링에 유용한 정보를 제공**한다.  
  
- 실습
  - 로그 수집기 간단 배치
  - 노드에 저장되는 로그 파일 원본 살펴보기
  - 표준 출력 스트림 또는 사이드카 컨테이너 경유 방식으로 출력 로그가 존재해야 한다.
  - timecheck 앱 2개 배치, 다른 네임스페이스
  - kubectl 로그 직접 살펴보기
  - cd ch13
  - kubectl apply -f timecheck/
  - kubectl wait --for=condition=ContainersReady pod -l app=timecheck -n kiamol-ch13-dev
  - kubectl logs -l app=timecheck --all-containers -n kiamol-ch13-dev --tail 1
  - kubectl wait --for=condition=ContainersReady pod -l app=timecheck -n kiamol-ch13-test
  - kubectl logs -l app=timecheck --all-containers -n kiamol-ch13-test --tail 1
  
위 실습 예제 방식으로 실제 클러스터에 사용한다면? -> 노드 출력 로그를 직접 다루기 너무 불편하다.  
별도 네임스페이스 지정, 어떤 파드에서 출력된 로그인지 분별 불가(옵션을 통해 인지 가능하긴 함)  
  
가장 심플한 방식은 kubectl을 사용하는 방식이지만, 노드에 저장되는 로그 파일을 수집 및 가공 한다면 다른 방법으로 로그를 볼 수 있다.  
- 실습
  - 호스트 경로 볼륨으로 로그 파일 경로 마운트하는 간단 sleep 디플로이먼트
  - 이 디플로이먼트를 통해 로그 파일 직접 확인 가능
  - 노드 접근 권한이 없어도 사용 가능
  - 호스트의 로그 파일 디렉터리를 마운트한 파드 실행 후 로그 파일 살펴보기
  - kubectl apply -f sleep.yaml
  - kubectl exec -it deploy/sleep -- sh
  - cd /var/log/containers/
  - ls timecheck*kiamol-ch13*_logger*
  - cat $(ls timecheck*kiamol-ch13-dev_logger*) | tail -n 1
  - exit
  
timecheck 앱 컨테이너는 사이드카 컨테이너를 경유해 로그를 출력한다.  
K8s 표준 로그 파일 명칭: 파드이름_네임스페이스_컨테이너이름-컨테이너식별자.log  
로그 파일 내용은 컨테이너 런타임에서 출력한 로그를 그대로 담은 JSON파일이다.  
  
대부분 K8s 구현체는 노드에 로그 로테이션 기능을 포함하고 있다.  
따라서 로그 파일 수집 후 중앙 저장소 전달시 한 곳에서 편하게 장기적인 관리가 가능하다.  
  
- 실습
  - 파드를 통해 현재 노드에서 실행되는 공통 코어 컴포넌트 체크 가능
  - kubectl exec -it deploy/sleep -- sh
  - cd /var/log/containers/
  - cat $(ls kube-proxy*) | tail -n 1
  - cat $(ls coredns*) | tail -n 1
  - cat $(ls kube-apiserver*) | tail -n 1
  - exit
  
노드에 포함된 모든 로그 파일 목록 확인 가능, 로그 뿐만 아니라 클러스터에서 발생한 문제 해결에 좋은 단서다.  
중앙화된 로그 시스템은 트러블 슈팅에 큰 도움이 된다.  
  
각 노드에서 로그 파일이 존재하고 이 파일을 수집해 중앙화된 저장소로 전달한다.  
로그 시스템을 일래스틱서치, 키바나, 플루언트디 EKF 스택을 이용한 구현 방법을 배워본다.  
  
# 13.2 플루언트디를 이용한 로그 파일 수집
플루언트 비트를 사용한다.  
K8s 구동 구조는 간단하다.  
모든 노드에서 콜렉터 파드를 데몬 셋 형태로 실행하고 호스트 경로를 마운트 해서 로그 파일에 접근할 수 있게 한다.  
  
- 실습
  - timecheck 앱의 로그 파일을 읽어 플루언트 비트 컨테이너의 표준 출력 스트림 출력 설정 배치
  - kubectl apply -f fluentbit/
  - kubectl wait --for=condition=ContainersReady pod -l app=fluent-bit -n kiamol-ch13-logging
  - kubectl logs -l app=fluent-bit -n kiamol-ch13-logging --tail 2
  
다른 네임스페이스에 존재하는 컨테이너의 로그를 플루언트 비트 컨테이너에서 출력됐다.  
즉 플루언트 비트가 노드 전체 로그를 수집했다.  
예를 들면 테스트 환경, 개발 환경 모두 중앙화된 저장소 한 곳에서 로그를 관리 할 수 있다.  
  
로그 수집은 간단하다. 로그 처리 파이프 라인 구성이 어렵다.  
플루언트 비트는 로그 파일 외 OS 로그를 포함한 다양한 유형의 로그를 수집 할 수 있다.  
- 로그 입력 -> 파싱 -> 필터 -> 출력 또는 제외 또는 채널별 전송
  
- 실습
  - 컨피그맵 업데이트 -> 플루언트 비트 설정을 K8s 필터 사용
  - 데몬셋 재시작하여 변경 적용 후 적용 체크
  - kubectl apply -f fluentbit/update/fluentbit-config-match.yaml
  - kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
  - kubectl wait --for=condition=ContainersReady pod -l app=fluent-bit -n kiamol-ch13-logging
  - kubectl logs -l app=fluent-bit -n kiamol-ch13-logging --tail 1

위에 예제는 로그를 콘솔로 출력하는 기능이고 플루언트 비트는 다양한 로그 출력 대상 플러그인을 지원한다.  
  
- 실습
  - 출력 대상 여러개 설정
  - kubectl apply -f fluentbit/update/fluentbit-config-match-multiple.yaml
  - kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
  - kubectl wait --for=condition=ContainersReady pod -l app=fluent-bit -n kiamol-ch13-logging
  - kubectl logs -l app=fluent-bit -n kiamol-ch13-logging --tail 2
  
# 13.3 수집된 로그를 일래스틱서치에 저장하기
일래스틱서치는 널리 쓰이는 오픈 소스 DB다.  
데이터를 도큐먼트 단위로 저장하고, 도큐먼트로 모인 것을 인덱스라 한다.  
  
인덱스 안에서도 도큐먼트는 동일한 스키마를 갖지 않는다.  
즉 도큐먼트는 제각각 다른 필드로 구성되고, 이런 특성 덕분에 다른 내용을 갖는 로그를 한 곳에 수집 가능하다.  
따라서 중앙화된 로그 시스템에 매우 적합하다.  
  
Rest API를 가진 단일 컴포넌트 형태로 실행되고, 키바나가 프론트엔드 역할을 맡는다.  
- 실습
  - 일래스틱서치, 키바나 배치
  - kubectl apply -f elasticsearch/
  - kubectl wait --for=condition=ContainersReady pod -l app=elasticsearch -n kiamol-ch13-logging
  - kubectl apply -f kibana/
  - kubectl wait --for=condition=ContainersReady pod -l app=kibana -n kiamol-ch13-logging
  - kubectl get svc kibana -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:5601' -n kiamol-ch13-logging
  
E, K의 디플로이먼트는 각각 파드 하나로 구성된다.  
키바나 레플리카 수를 늘려 로그 시스템의 고가용성을 확보할 수 있다.  
  
일래스틱서치는 스토리지 공유를 통해 여러 파드에 걸쳐 동작하는 스테이트풀셋 형태나 클라우드에서 실행되는 매니지드 서비스 형태로 사용 할 수 있다.  
  
플루언트 비트는 일래스틱서치를 출력 대상으로 하는 플러그인을 지원한다.  
즉 로그 엔트리 하나하나를 일래스틱 rest api를 통해 도큐먼트로 저장한다.  
  
k8s 매니페스트에 Match에 일치하지 않는 정보는 폐기된다.  
- 실습
  - 일래스틱서치 로그 저장 플루언트 비트 설정 
  - kubectl apply -f fluentbit/update/fluentbit-config-elasticsearch.yaml
  - kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
  - kubectl wait --for=condition=ContainersReady pod -l app=fluent-bit -n kiamol-ch13-logging
  
키바나는 완전히 자동화가 아니라, 로그 UI 조작이 필요하다.  
일래스틱 서치와 키바나를 통해 필드 목록(파드 이름, 호스트 노드, 컨테이너 이미지 등)을 통해 로그 필터링을 할 수 있다.  
따라서 통계 체크 및 대시보드를 통해 오류 및 급증 트래픽 등 이상 현상을 쉽게 발견 할 수 있다.  
  
- 실습
  - 중앙화된 로그 시스템 장점 체험하기
  - 무작위 숫자 API 배치
  - 2번 째 요청부터 에러, 그러나 프록시 서버를 통해 캐싱하여 에러 X
  - 키바나를 통해 오류 식별 검색
  - kubectl apply -f numbers/
  - kubectl wait --for=condition=ContainersReady pod -l app=numbers-api -n kiamol-ch13-test
  - kubectl get svc numbers-api-proxy -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8080/rng' -n kiamol-ch13-test
  - 키바나 검색
    - kubernetes.labels.app:numbers-api AND log:<API 출력 오류 식별자>
  
검색 가능한 중앙화된 로그 시스템은 너무 좋다.  
모든 구성이 오픈 소스에 여러 환경에 동일 기술 스택을 적용할 수 있다.  
유용한 정보를 로그에 담아 문제 해결이 병목이 발생하지 않도록 로그를 잘 설계해야 한다.  
  
# 13.4 로그 파싱 및 필터링하기
로그 엔트리 심각도, 생산 객체, 이벤트 유형, 식별자 등의 필드로 구조화된 로그를 생상한 수 있다.  
이 필드를 통해 필터링하고, 원하는 로그를 정확히 검색 할 수 있다.  
하지만 대부분 시스템은 이상적인 로그 생산 환경이 아니다.  
  
- 실습
  - 파서 사용, 키바나를 통해 정교한 대상 설정 및 로그 필터링
  - kubectl apply -f fluentbit/update/fluentbit-config-parser.yaml
  - kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
  - kubectl wait --for=condition=ContainersReady pod -l app=fluent-bit -n kiamol-ch13-logging
  - kubectl apply -f numbers/update/
  - kubectl wait --for=condition=ContainersReady pod -l app=numbers-api -n kiamol-ch13-test
  
로그 시스템과 앱을 분리함으로써 앱 재시작 없이 로그 수준 조절을 하는 것이 이상적이다.  
- 실습
  - priority의 특정 수준 이상만 수집하도록 설정
  - kubectl apply -f fluentbit/update/fluentbit-config-grep.yaml
  - kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
  - kubectl delete pods -n kiamol-ch13-test -l app=numbers-api
  - kubectl wait --for=condition=ContainersReady pod -l app=numbers-api -n kiamol-ch13-test
  - kubectl logs -n kiamol-ch13-test -l app=numbers-api
  
# 13.5 쿠버네티스에 적용할 수 있는 그 외 로그 모델
K8s는 기본적으로 앱 로그를 컨테이너 표준 출력 스트림으로 간주한다.  
앱에서 일래스틱서치로 곧바로 로그를 기록하는 방식, 모든 앱 파드에 로깅 사이드카 컨테이너를 추가하는 방식 등 상황에 맞게 사용하면 된다.  
  
**앱이 표준 출력 스트림으로 로그를 출력하지 않으면 사이드카 컨테이너가 필요하다.**  
  
커스텀 정의 로그 프레임워크는 k8s 초기에 고려해볼 수 있는 선택이다.  
OS를 통해서 로그 출력하는 환경과, 일래스틱서치로 로그를 바로 출력한다는 환경이 상이한 상황이 올 수도 있다.  
  
- 실습
  - 제거
  - kubectl delete ns -l kiamol=ch13
  - kubectl delete all -l kiamol=ch13
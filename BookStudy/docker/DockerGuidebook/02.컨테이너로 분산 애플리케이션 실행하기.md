앱은 대게 여러 요소로 분할 돼 구성된다.

# 7장 도커 컴포즈로 분산 애플리케이션 실행하기
도커는 n-티어 모놀리식 설계부터 MSA 설계까지 분산 컴포넌트 관리에 이상적이다.

## 7.1 도커 컴포즈 파일의 구조
Dockerfile 스크립트는 애플리케이션을 패키징을 위한 스크립트다.
Dockerfile 스크립트 = App Packaging 스크립트

분산 앱은 단지 한 부분을 패키징하는 수단으로 보면 된다.
백 / 프론트로 나뉜 경우 두 개의 도커 파일이 필요하다.
백엔드가 MSA로 여러 도메인으로 분할 관리하는 경우, 다시 n개만큼 도커 파일이 필요하다.

직접 순서대로 여러 도커파일을 수동으로 옵션을 지정해 실행 할 수 있지만,
실수 가능성이 높아진다. 심지어 앱 동작의 문제가 생길 수 있다.
이런 경우 도커 컴포즈 파일에 앱 구조를 정의하면 된다.

컨테이너 실행시 지정할 모든 옵션과 도커 네트워크, 볼륨 등 도커 API에 명령을 내린다.

ex)
```dockerfile
verison: '3.7'

services:
    todo-web:
        image: diamol/ch06-todo-list
        ports:
            - "8020:80"
        networks:
            - apt-net
networks:
    app-net:
        external:
            name: nat
```
- 도커 컴포즈는 문법이 이해하기 쉽고, json 변환에 용이한 YAML 문법으로 기술된다.
- 예제상 세 개의 최상위 문으로 구성된다.
  1. version
     - 도커 컴포즈 파일 형식 버전
  2. services
     - 앱 구성 모든 컴포넌트 열거
     - 실제 컨테이너 대신 서비스 개념을 단위로 삼는다.
  3. networks
     - 서비스 컨테이너가 연결될 모든 도커 네트워크 열거
- diamol/ch06-todo-list 이미지를 통해 단일 컨테이너로 실행된다.
- 컨테이너의 80번 포트를 호스트 컴퓨터 8020번 포트를 통해 공개한다.
- app-net 정의된 app-net 도커 네트워크에 접속
- 서비스 이름은 컨테이너 이름이자 도커 네트워크상 다른 컨테이너가 식별할 수 있게 한다.
- 서비스 구성 네트워크는 app-net
- app-net 네트워크는 net이라는 외부 네트워크로 연결된다.
- external 의미는 nat 네트워크는 이미 존재하므로, 새로 생성하지말라는 것이다.
  - 여기에 설정된 네트워크가 존재하지 않는 경우 도커 네트워크를 생성한다.


도커 컴포즈는 도커 명령과는 다르게, 앱 실행을 위해 up 명령을 실행해야 한다.
up을 통해 컴포즈 파일 체크, 정의된 상태로 실행하기 위해 필요 요소 준비를 시작

실습) 도커 네트워크 생성, 예제를 받은 후 도커 컴포즈 실행해보기
- docker network create nat
- cd ./ch07/exercises/todo-list
- docker-compose up

docker-compose up 실행시 현재 작업 디렉토리에서 docker-compose.yml 파일을 찾는다.
그리고 서비스들을 읽어들이고, 설정한 이미지를 내려 받고, 컨테이너를 실행하고, 컨테이너는 정의된대로 동작한다.
또한 간접적으로 문서화 효과를 얻을 수 있다.
단일 서비스라면 몰라도 여러 서비스로 구성된 도커 컨테이너는 도커 컴포즈 파일이 꼭 필요하다.

## 7.2 도커 컴포즈를 사용해 여러 컨테이너로 구성된 애플리케이션 실행하기
도커 컴포즈를 통해 여러 서비스의 환경 변수, 명령 등을 정의하고, 서비스 간 통신을 자유롭게 할 수 있다.

```yaml
accesslog:
  image: diamol/ch04-access-log

iotd:
  image: diamol/ch04-image-of-the-day
  ports:
    - "80"
      
image-gallery:
  image: diamol/ch04-image-gallery
  ports:
    - "8010:80"
  depends on:
    - accesslog
    - iotd

# 네트워크 부분 생략
```
- accesslog는 공개 ports도 없이 이미지만 입력됐다.
- iotd는 rest api로, 80번 포트를 외부 무작위 포트를 통해 공개
- image-gallery도 외부 포트 공개, 다른 두 서비스에 의존한다는 것을 입력
  - 의존성 코드를 통해 나열된 두 서비스를 먼저 실행하려고 한다.

도커 컴포즈를 통해 분리 모드로 앱 실행해보자.
도커 컴포즈는 컨테이너 로그를 수집하지만, 컨테이너는 백그라운드로 동작한다. 
따라서 컴포즈의 기능을 사용해볼 수 있다.
실습) 예제 앱 실행해보기
- cd ./ch07/exercises/image-of-the-day
- docker-compose up --detach
    - --detach 명령을 통해 컨테이너가 백그라운드로 실행되어, 명령 실행창에 로그 출력이 없다.
실습) 도커 컴포즈를 사용해 iotd 서비스 컨테이너 수 늘리고, iotd 컨테이너 로그 살펴보기
- docker-compose up -d --scale iotd=3
- docker-compose logs --tail=1 iotd
  - --tail1=1 파라미터는 iotd 컨테이너의 마지막 로그를 출력하라는 의미다.

iotd 서비스 컨테이너를 총 세개로 관리하고, 해당 서비스에 api 요청시 세 개의 컨테이너에 고르게 분배해준다.
logs를 활용해 스케일링된 세 개의 컨테이너에 요청이 왔는지 체크 할 수 있다.

이처럼 도커 컴포즈가 대신 컨테이너들을 관리해준다.
하지만 도커 컴포즈를 통해 전체 앱을 관리할 수 있지만,
컴퓨팅 자원 절약을 위해 컨테이너 중지, 재시작, 재가동 등의 작업은 도커 명령행을 통해 할 수 있는 작업이다.
도커 컴포즈를 통해 컨테이너 관리를 돕지만, 내부적으로는 마찬가지로 도커 API를 사용한다.
따라서 도커 컴포즈를 통해 실행한 컨테이너도 도커 명령으로 관리 가능하다.
실습) 앱 중지, 재시작 후 실행 중인 컨테이너 목록 출력
- docker-compose stop
  - 중지된 모든 컨테이너는 CPU, 메모리를 점유하지 않지만, 컨테이너의 파일 시스템은 유지한다.
- docker-compose start
  - up과 start의 차이점 알기
  - 다시 앱 시작시 기존에 생성되었던 컨테이너가 재시작
- docker container ls

- docker-compose 
  - docker-compose --help와 마찬가지로, 전체 부명령 목록 체크 가능

도커 컴포즈는 클라이언트 측에서 동작하는 도구다.
도커 컴포즈 명령에 따라 도커 API로 지시를 보낸다.

도커 엔진 자체는 컨테이너를 실행할 뿐, 여러 컨테이너가 어떤 앱에서 동작하는지 여부는 알 수 없다.
따라서 도커 컴포즈를 통해 파일 작성 후 도커 엔진이 이 파일을 읽을 수 있게 해야 한다.

컴포즈 파일 수정 또는 도커 명령을 통해 앱 수정시 앱과 불일치 할 수 있다.
불일치 상태에서 비정상적인 동작을 보일 수 있다.
실습) 도커 컴포즈를 통해 앱 재시작하고 스케일링 상태 확인해봐라, 3개인지 체크
- docker-compose down
  - 앱 제거 명령, 앱 중지되고, 컨테이너 모두 제거된다. external 플래그가 없다면 볼륨과 네트워크도 제거 대상
- docker-compose up -d
- docker container ls

도커 컴포즈는 사용하기 쉽고, 강력한 기능을 갖췄다.
하지만 yaml의 컴포즈 파일 정의에 의존하는 클라이언트 측 도구임을 잊지말자.

도커 컴포즈로 앱 배포시 다양한 리소스가 생성되지만, 도커 엔진은 단순히 컨테이너를 실행할 뿐이다.
리소스 관리는 컴포트 파일을 통해 관리하자.

## 7.3 도커 컨테이너 간의 통신
분산 앱의 모든 구성 요소는 컴포즈를 통해 관리되고 컨테이너로 실행된다.

그렇다면 컨테이너간 통신은 어떻게 할까?
컨테이너는 별도 네트웤 공간을 가진 가상 환경이다.
도커 엔진으로부터 부여받은 가상 IP 주소를 가지며, 도커 네트워크로 연결하여 가상 IP를 통해 통신할 수 있다.
그러나 컨테이너 교체시 가상 IP 주소도 변경된다.
변경돼도 통신을 유지할 수 있도록 도커에 내장된 DNS 서비스를 이용해 서비스 디스커버리 기능을 제공한다.

DNS는 인터넷과 사설 네트워크 모두 동작한다.
컴퓨터는 IP를 알아내 실질적으로 통신을 수행하지만, 사람에게 친숙한 것은 도메인이다.
IP는 주소가 변경될 수 있고, 외우기 쉽지 않기 때문이다.

도커 내장 DNS 서비스를 통해 컨테이너의 가상 IP를 찾아준다.
이를 통해 같은 도커 네트워크에 있는 다른 컨테이너 정보를 사용 가능하다.
도메인의 대상이 IP가 아니라면, 호스트 컴퓨터의 네트워크나 인터넷 IP 주소를 조회한다. (?)
실습) 도커 컴포즈를 통해 iotd 컨테이너를 스케일업해서 실행 후 컨테이너에서 DNS 조회 명령 실행
- docker-compose up -d scale --iotd=3 (?)
  - docker-compose up -d --scale iotd=3
- docker container exec -it image-of-the-day_image-gallery_1 sh
  - nslookup accesslog
    - 웹 앱 컨테이너 기반 이미지의 유틸리티, 명령 인자로 도메인 지정시 해당 도메인 DNS 서비스 조회, 결과 출력 
  - exit

도커 네트워크에 연결된 모든 컨테이너는 이 네트워크 범위에 포함되는 가상 IP 주소를 부여받는다.
해당 네트워크를 통해 컨테이너간 통신이 가능하다.
DNS 조회를 사용하면, 컨테이너 교체로 IP 주소가 변경돼도 컨테이너에 접근 가능하다.
실습) 도커 명령으로 accesslog 컨테이너 삭제, 도커 컴포즈 재 실행, 웹 컨테이너 셸 실행 후 DNS 재 조회
- docker container rm -f image-of-the-day_accesslog_1
- docker-compose up -d --sacle iotd=3
- docker container exec -it image-of-the-day_image-gallery_1 sh
  - nslookup accesslog
  - nslookup iotd
  - exit

삭제되고 새로 생성된 컨테이너는 도커 엔진으로부터 가상 IP를 새로 부여받는다.
또한 iotd와 같이 하나의 도메인에 dns 조회시 각 컨테이너를 가리키는 세 개의 가상 ip주소가 출력된다.
도커 컴포즈는 이 점을 활용해 간단 로드 밸런싱 구현 가능하다.
여러 개 IP 주소를 어떻게 활용할지는 전적으로 애플리케이션이 결정한다.
간단한 조회는 첫 번 째 IP만 사용하게 할 수 있고, 모든 컨테이너에 고르게 분배할 수도 있다.
도커 DNS 시스템은 조회 결과의 순서를 매번 변화시킨다.
nslookup을 활용해 컨테이너간 트래픽 고르게 분산 가능하다.

도커 컴포즈는 컨테이너 실행시 지정된 모든 옵션 값을 기억하고, 옵션 값을 통해 컨테이너간 통신을 처리한다.
네트워크에 포함된 가상 IP 범위가 있고, 
컨테이너 삭제시 해당 가상 IP는 재사용 가능 상태가 된다.
따라서 컨테이너 삭제 후 생성해도, 같은 IP를 우연하게 사용 가능하다.

## 7.4 도커 컴포즈로 애플리케이션 설정값 지정하기
앱 컨테이너를 단일로 실행하고, 데이터는 SQLite 데이터베이스에 저장한다면?
이 경우 컨테이너 안 파일 하나만 있으면 된다.

그러나 소규모 프로젝트가 아닌 경우는 SQLite는 애매하다.
PostgreSQL을 사용해보도록 하자.
앱 컨테이너와 데이터베이스 컨테이너를 따로 실행해 분산 앱으로 구동 할 수 있다.
도커 컴포즈를 사용해 설정 값 적용해보자.

```yaml
services:
  todo-db:
    image: diamol/postgres:11.5
    ports:
      - "5433:5432"
    networks:
      - app-net
  todo-web:
    image: diamol/ch06-todo-list
    ports:
      - "8020:80"
    environment:
      - Database: Provider=Postgres
    depends_on:
      - todo-db
    networks:
      - app-net
    secrets:
      - source: postgres-connection
        target: /app/config/secrets.json
```
- environment: 컨테이너 안 사용될 환경 변수 값 정의
- secrets: 실행시 컨테이너 내부 파일에 기록될 비밀 값 정의, target에 정의된 파일이 생기고, source 값이 비밀 값의 값이 기록된다.

비밀 값은 주로 클러스터 환경에서 컨테이너 플랫폼을 통해 제공된다 (쿠버, 도커 스웜, ...)
평소에는 클러스터 데이터베이스에 암호화되어 있고 패스워드, 인증서, API 키 등 민감한 정보로 구성된 설정 값 전달에 적합하다.

```yaml
secrets:
  postgres-connection:
    file: ./config/secrets.json
```
- 비밀 값 postgres-connection의 값을 ./config/secrets.json 파일에서 읽어오라는 의미다.
- 호스트 컴의 파일이 컨테이너에 영향을 미친다는 점에서 바인드 마운트와 비슷하다.
  - 추후 클러스트 환경에서 암호화된 진짜 비밀 값으로 이전 여지를 남겨둔 것

앱의 설정 값을 컴포즈 파일에 정의시 이미지를 다양하게 활용 할 수 있다.
실습) 예제 도커 컴포즈 업 하기
- cd ./ch07/exercises/todo-list-postgres
- docker-compose up -d
- docker-compose ps
  - 컴포즈 파일에 정의된 모든 컨테이너 목록을 보여준다.

패키징된 앱과 설정 값을 분리할 수 있는 것이 도커의 핵심 장점 중 하나다.
앱 이미지는 빌드 파이프 라인을 통해 만들어지고 테스트 환경을 거쳐 운영 환경 적합한지 검증된다.

## 7.5 도커 컴포즈도 만능은 아니다.
도커 컨테이너의 본격적 사용을 위해 도커 컴포즈는 매우 중요한 도구다.
도커 컴포즈는 도커 스웜이나 쿠버네티스 같은 완전한 컨테이너 플랫폼은 아니다.
즉 앱이 지속적으로 정의된 상태를 유지하도록 하는 기능은 없다.
일부 컨테이너가 오류 또는 종료가 돼도 docker-compose up 명령을 다시 실행하지 않는 한 앱의 상태를 되돌릴 수 없다.

운영 환경에서는 도커 컴포즈보단, 도커 스웜이나 쿠버네티스가 쓰인다.
그러나 앱 정의에는 컴포즈파일 포맷을 사용한다.

도커 컴포즈가 모든 운영 환경에서 부적합하다는 것은 아니다.
컨테이너 클러스터의 운영 계획이 없는 한 도커 컴포즈로도 충분하다.

## 7.6 연습 문제

# 8장 헬스 체크와 디펜던시 체크로 애플리케이션의 신뢰성 확보하기
실행중인 컨테이너 앱을 운영 환경에 맞게 다듬을 수 있다.
도커 스웜이나 쿠버네티스 등과 같은 컨테이너 플랫폼을 통해 자동으로 에러에서 회복 할 수 있는 기능을 제공한다.
실행 중인 컨테이너의 앱이 상태가 정상인지 체크하는 정보가 이미지와 함께 패키징 되어 있다.
이를 통해 비정상 컨테이너 삭제 후 새 컨테이너로 대체한다.

## 8.1 헬스 체크를 지원하는 도커 이미지 빌드하기
도커는 컨테이너 시작 시점에 앱의 기본 상태를 확인한다.
컨테이너 실행시 앱 실행 파일이나 특정한 프로세스가 실행되는데, 도커는 이 프로세스의 실행 상태를 확인한다.
만약 종료되었다면, 컨테이너도 함께 종료된다.
이를 통해 기본적인 헬스 체크를 한다.

클러스터 환경에서 종료된 컨테이너를 재시작하거나 새 컨테이너로 교체하는 작업을 대신 해 준다.
그러나 오류를 맞이한 동일한 상황이 오면 또 컨테이너는 재시작하거나 교체하는 작업이 필요해진다.
앱의 동작이 멈춰도 도커는 컨테이너를 정상이라 판단한다.

도커는 앱의 상태가 실제 정상인지 확인하는 정보를 직접 넣을 수 있는 똘똘한 기능을 제공한다.
Dockerfile 스크립트에 상태 확인 로직을 추가하면 된다.

먼저, 헬스 체크 로직이 없는 상태에 생길 수 있는 문제 먼저 체험해보자.
실습) 예제 앱 실행, 비정상 상태 유도, ...
1. docker container run -d -p 8080:80 diamol/ch08-numbers-api
   - API 컨테이너 실행
2. API 세 번 호출
   - curl http://localhost:8080/rng
   - curl http://localhost:8080/rng
   - curl http://localhost:8080/rng
   - curl http://localhost:8080/rng
     - 네 번 째 호출에서 실패 
     - 그러나 도커 컨테이너는 실행중

Dockerfile의 HEALTHCHECK 인스트럭션 사용해보기
컨테이너 런타임은 이 정보를 이용해 동작중인 앱의 상태가 정상인지 체크 가능하다.
이 인스트럭션을 통해 도커가 컨테이너 안에서 실행하는 명령어 지정 가능하다.
이 명령의 반환 상태 코드를 보고 앱의 상태를 판단한다.
앱 상태 판단 가능한 어떤 명령을 지정해도 무방하다.

도커는 컨테이너 안에서 주기적으로 지정된 명령을 실행한다.
이를 통해 일정 횟수 실패시 컨테이너를 이상 상태로 간주한다.

```dockerfile
FROM diamol/dotnet-aspnet

ENTRYPOINT ["dotnet", "/app/Numbers.Api.dll"]
HEALTHCHECK CMD curl --fail http://localhost/health

WORKDIR /app
COPY --from=builder /out/ .
```
- 위에 실습과 다른 점은 API 호출이 컨테이너 내부에서 실행된다는 점이다.
- 헬스 체크시 엔드포인트 /health로 http 요청을 보낸다.
- --fail 옵션 사용시 curl이 전달받은 상태 코드를 도커에 전달한다. (성공: 0, 실패: 0 외에 다른 숫자)

Dockerfile 스크립트의 파일명이나 경로가 다른 경우 부 명령을 이용하면 된다.
실습) 터미널로 최상위 디렉토리 이동, 다른 경로 도커파일 태그 부여해 이미지 빌드
- cd ./ch08/exercises/numbers
  - 최상위 디렉토리 이동
- docker image build -t diamol/ch08-numbers-api:v2 -f ./numbers-api/Dockerfile.v2 .

헬스 체크 간격과 누적 실패 횟수도 설정 가능하다.
기본 값은 30초 간격 연속 3회 실패시 앱을 이상 상태로 간주한다.

실습) 다시 실행해보기
- docker container run --rm -d -p 8081:80 diamol/ch08-numbers-api:v2
- docker container ls
- curl http://localhost:8081/rng
- curl http://localhost:8081/rng
- curl http://localhost:8081/rng
- curl http://localhost:8081/rng
  - api 실패 유발
- docker container ls
  - 이상 상태 감지 체크
  - 90초 지나고 health 상태에서 unhealth가 된다.

컨테이너 이상 상태는 도커 API를 통해 보고된다.
따라서 애플리케이션 내에 오류가 존재하지만, 컨테이너가 실행중일 때도 복구를 위한 조치 가능하다.
뿐만 아니라 가장 최근 헬스 체크 수행 결과도 저장돼 있어 확인 가능하다.
docker container inspect 명령을 통해 확인 가능하다.

실습) 가장 최근 만든 컨테이너 상태 출력
- docker container inspect $(docker container ls --last 1 --format '{{.ID}}')
  - State 필드 확인

그러나 컨테이너 상태를 확인하면 컨테이너는 여전히 실행 중 상태다. 
컨테이너 재시작 또는 새 컨테이너로 교체는 어떻게 할까?

도커는 이런 작업을 안전하게 처리할 순 없다.
재시작하면 애플리케이션은 완료될 때 까지 동작하지 않는다.
그 사이의 데이터 유실 될 수 있고 상황이 더 악화될 수 있다.
따라서 컨테이너를 그대로 두는 것이 최선이다.
또한 일시적인 unhealth는 컨테이너 상태는 다시 health 해진다.
도커 스웜이나 쿠버네티스 같은 클러스터 환경에서는 헬스 체크 기능이 더욱 유용하다.
헬스 체크를 통해 컨테이너 이상 상태 통보를 통해 자동 조치 가능한 덕분이다.
클러스터는 컨테이너 추가 실행 여력이 충분하기에 잘 활용될 수 있다.
즉 이상 상태 컨테이너를 두고, 대체 컨테이너를 실행해 앱의 중단 시간 없이 상태 회복 가능하다.

## 8.2 디펜던시 체크가 적용된 컨테이너 실행하기
여러 컨테이너에 나뉘어 실행되는 분산 앱은 또 하나의 문제를 겪을 수 있다.
컨테이너 교체시 컨테이너간 의존 관계를 고려하지 않는다.
동작하는 서버가 한 대라면, 특정 서버 먼저 실행되도록 보장할 수 있지만, 
클러스터 환경의 컨테이너 플랫폼은 컨테이너의 실행 순서까지 통제할 수 없다.
그래서 선 실행 되어야 할 컨테이너가 후 실행 되는 상황이 올 수 있다.

실습) 실행 중 모든 컨테이너 제거, 시키는대로 해보기 (서적 참고)
- docker container rm -f $(docker container ls -aq)
- docker container run -d -p 8082:80 diamol/ch08-numbers-web
- docker container ls

제대로 동작해보이지만, 내부 연관된 컨테이너가 동작되지 않아 에러가 발생한다.
컨테이너는 정상이지만, 애플리케이션간 의존관계를 만족하지 않아 비정상 동작을 유발하게 된다.
애플리케이션 중 필요 의존 관계 미리 체크하는 로직을 넣는 것이 가능한 앱도 있다.

의존관계 만족하는지 점검하는 디펜던시 체크 기능도 도커 이미지에 추가할 수 있다.
앱 실행 전 필요 요구사항 확인하는 기능으로 모든 요구 사항 확인 후 디펜던시 체크 성공하면 앱이 실행된다.

디펜던시 체크는 별도의 인스트럭션을 갖고 있진 않고, 애플리케이션 실행 명령을 통해 로직을 추가해야 한다.
CMD 인스트럭션을 통해 앱 실행 전 API 사용 가능 여부 체크
```dockerfile
FROM diamol/dotnet-aspnet

ENV RngApi:Url=http://numbers-api/rng

CMD curl --fail http://numbers-api/rng && dotnet Numbers.web.dll

WORKDIR /app
COPY --from=builder /out/ .
```
- API 사용 가능 여부 체크를 위해 기반 이미지에 포함된 유틸리티 curl를 활용
- CMD 인스트럭션에 정의된 명령은 컨테이너 실행할 때 실행된다.
  - and 조건으로 두 조건이 모두 성공시 실행된다.
  - 하나라도 실패시 컨테이너는 그대로 종료된다.

실습) 서적에서 시키는대로 하기 (p.215)
- docker container run -d -p 8084:80 diamol/ch08-numbers-web:v2
- docker container ls -all

CMD를 통해 의존관계 컨테이너가 실행되어 있지 않아서 컨테이너는 실행되지 않는다.
직관적이지 않지만, 이 상황에서는 컨테이너가 실행되지 않는 것이 그나마 괜찮다.

헬스 체크와 디펜던시 체크를 통해 컨테이너 플랫폼 환경에 적합한 앱이라고 판단하면 된다.
디펜던시 체크에 사용된 것은 CMD 인스트럭션의 curl로, 가장 기본적인 http 요청 테스트다.
단순한 방식으로 체크가 보장된다면 별도의 외부 도구는 필요하지 않다.

## 8.3 애플리케이션 체크를 위한 커스텀 유틸리티 만들기
curl는 웹앱 또는 API 테스트시 매우 유용한 도구다.
하지만 실무에서 앱 테스트 목적으로 curl를 사용하진 않는다.
보안 정책상 도커 이미지에 curl를 포함시킬 수 없다.

도커 이미지에는 앱 구동을 위해 필요한 최소 내용만 가져야 한다.
curl는 컨테이너 상태 체크에 유용한 도구이지만, 현업에서는 프로그래밍 언어로 구현된 별도 커스텀 유틸리티를 사용하는 것이 좋다.

- 프로그래밍 언어로 구현된 커스텀 유틸리티 장점
  1. 이미지에 추가적인 소프트웨어를 포함시킬 필요 없다.
  2. 조금 더 구체적인, 예를 들면 재시도 횟수, 분기 등 복잡한 체크 로직 적용 가능
  3. URL 여러 곳 정의되거나, 수정시 누락 방지 가능
  4. 컨테이너 실행 전 체크가 필요한 모든 사항 검증 가능

다양한 상황에서도 동작 가능한 장점으로, curl 보단 애플리케이션 언어로 디펜던시 체크 등 컨테이너 상태를 체크하자.

```dockerfile
FROM diamol/dotnet-aspnet

ENTRYPOINT ["dotent", "Numbers.Api.dll"]
HEALTHCHECK CMD ["dotnet", "Utilities.HttpCheck.dll", "-u", "http://localhost/health"]

WORKDIR /app
COPY --from=http-check-builder /out/ .
COPY --from=builder /out/ .
```

실습) 책에서 시키는대로.. (p.219)
- docker container rm -f $(docker contaoner ls -aq)
  - 기존 컨테이너 모두 삭제
- docker container run -d -p 8080:80 --health-interval 5s diamol/ch08-numbers-api:v3
  - 헬스 체크 간격 5초로 설정, 기본 15초
- docker container ls
- curl http://localhost:8080/rng
- curl http://localhost:8080/rng
- curl http://localhost:8080/rng
- curl http://localhost:8080/rng
  - 실패 유발
- docker container ls
  - 15초 후 이상 상태 변경 체크

헬스 체크를 닷넷으로 구현된 Http 테스트 유틸리티를 사용하면서 다양한 상황에 대응에 유연하다.
디펜던시 체크도 마찬가지로 같은 유틸리티 사용했다.

```dockerfile
FROM diamol/dotnet-aspnet

ENV RngApi:Url=http://numbers-api/rng
CMD dotnet Utilities.HttpCheck.dll -c RngApi:Url -t 900 && dotent Numbers.Web.dll

WORKDIR /app
COPY --from=http-check-builder /out/ .
COPY --from=builder /out .
```
- 이미지에 curl 제거하고, 헬스 체크와 디펜던시 체크를 유지했다.

실습) 책에서 시키는대로.. (p.221) 
- docker container run -d -p 8081:80 diamol/ch08-numbers-web:v3
- docker container ls --all

커스텀 테스트 유틸리티를 통해 이미지 이식성이 향상된다.
컨테이너 플랫폼마다 헬스 체크와 디펜던시 체크를 정의하고 실행하는 방법에는 차이가 있다.
그러나 커스텀 테스트 유틸리티를 통해 어떤 환경에서도 그대로 동작 가능하다.

## 8.4 도커 컴포즈에 헬스 체크와 디펜던시 체크 정의하기
도커 컴포즈는 앱 상태 이상시 어느 정도 복원 가능한 기능이 있다.
그러나 새 컨테이너로 대체하진 않는다.
종료된 컨테이너를 재시작하거나, 이미지에 정의되지 않은 헬스 체크 추가 가능하다.

```yaml
numbers-api:
  image: diamol/ch-numbers-api:v3
  ports:
    - "8087:80"
  healthcheck:
    interval: 5s
    timeout: 1s
    retries: 2
    start_period: 5s
  networks:
    - app-net
```
- 도커 컴포즈는 헬스 체크 옵션 더 상세하게 설정 가능
- interval: 헬스 체크 간격
- timeout: 제한 시간, 응답받지 못하면 실패로 간주
- retries: 실패 횟수, 채우면 이상 상태로 된다.
- start_period: 컨테이너 실행 후 첫 헬스 체크 실시 간격

헬스 체크 실시할 때 CPU와 메모리 자원이 필요하므로, 운영 환경에서는 좀 더 너프하게 잡으면 된다.
이미지에 헬스 체크를 안 하는 경우, 애플리케이션 언어와 도커 컴포즈를 통해 정의하는 방법이 있다.

```yaml
numbers-web:
  image: diamol/ch08-numbers-web:v3
  restart: on-failure
  ports:
    - "8088:80"
  healthcheck:
    test: ["CMD", "dotnet", "Utilities.HttpCheck.dll", "-t", "150"]
    interval: 5s
    timeout: 1s 
    retries: 2  
    start_period: 10s
  networks:
    - app-net
```
모든 컨테이너에 헬스 체크 적용 뿐 아니라, 이미지에 디펜던시 체크 포함돼 있다.
restart: on-failure를 통해 얘기치 않은 종료시 컨테이너를 재시작한다.
그러나 의존 관계 정의한 depends_on 설정이 없으므로, 컨테이너 실행 순서가 정의되지 않았다.

실습) 책에서 시키는대로.. (p.226)
- cd ./ch08/exercises/numbers
- docker container rm -f $(docker container ls -aq)
- docker-compose up -d
- docker container ls
- docker container logs numbers_numbers-web_1

도커 컴포즈를 내의 depends_on을 통해 디펜던시 체크를 직접 하지 않는 이유는,
도커 컴포즈가 디펜던시 체크 가능 범위가 단일 서버로 제한되어 있다.
운영 환경은 예측이 어렵기 때문에, depends_on 보단 프로그래밍 언어 테스트 유틸리티를 활용하자.

## 8.5 헬스 체크와 디펜던시 체크로 복원력 있는 애플리케이션을 만들 수 있는 이유
분산 시스템 앱은 유연성과 기민성이 뛰어나다.
그러나 그만큼 관리가 어렵다.

분산 시스템의 의존 관계 컨테이너가 너무 많다면 어떡할까?
디펜던시 체크와 헬스 체크 활약이 바로 이 지점이다.
두 체크를 도입하여 플랫폼 실행 순서를 보장할 필요 없다.
가능한 빨리 컨테이너를 실행하면 된다.
일부 컨테이너 의존 관계 만족되지 않으면 해당 컨테이너는 재실행 또는 새 컨테이너로 교체된다.

컨테이너가 재실행되고, 교체될 순 있어도 애플리케이션은 빠르게 계속 동작 가능하다.
앱 가동시 생애주기로, 오류 발생으로 헬스 체크가 연속으로 실패하면 새로운 컨테이너를 만들어 실행 후 기존 컨테이너를 종료한다.

하지만 헬스 체크와 디펜던시 체크는 주의가 필요하다. 즉 시스템 부하를 일으키면 안 된다.
따라서 애플리케이션이 실제 동작 중인이 검증하는 핵심만 최소한으로 테스트 돼야 한다.
디펜던시 체크는 앱 시작 시점에만 실행되므로, 너무 크게 신경 쓸 필요는 없다.

## 8.6 연습 문제

# 9장 컨테이너 모니터링으로 투명성 있는 애플리케이션 만들기
앱의 자동 스케일링 기능은 트래픽 부하에 적절하게 규모를 조절하고, 간헐적 오류에 스스로 복원 가능하다.
헬스 체크 기능만 사용해도 상당히 유용하다.

그래도 지속적인 모니터링과 이상 증후에 대한 통보 기능은 필요하다.
프로메테우스를 사용해 앱 컨테이너의 측정 수치를 수집하고,
그라파나를 사용해 수치를 시각화해 대시보드 형태로 구성한다.

## 9.1 컨테이너화된 애플리케이션에서 사용되는 모니터링 기술 스택
프로메테우스 역시 컨테이너에서 동작한다.
따라서 분산된 앱 컨테이너를 어렵지 않게 모니터링 가능하다.
도커 엔진과 컨테이너들로부터 데이터 수집하고 외부 공개 API를 포함해 컨테이너를 만든다.

도커 엔진 설정에서 프로메테우스 측정 기능을 명시적 활성화해야 한다.
도커 데스크탑을 활용해 daemon.json 파일 수정
실습) daemon.json 설정 값 추가
- "metrics-addr" : "0.0.0.0:9323"
- "experimental" : true

9323 포트를 통해 측정 값이 공개된다.
도커 엔진 설정 파일 변경만 해도,
localhost:9323/metrics를 통해 상태 정보가 프로메테우스 포맷으로 제공된다.

실습) p.240 책에 적힌대로
- hostIP=$(ifconfig en0 | grep -e 'inet\s' | awk '{print $2}')
- docker container run -e DOCKER_HOST=$hostIP -d -p 9090:9090 diamol/prometheus:2.13.1
  - 호스트 컴퓨터와 통신하고, 도커 엔진 상태 측정 값 수집

주기적으로 도커 호스트에서 측정 값 수집 후 디비에 저장하고, 이를 조회 가능한 웹 인터페이스가 실행됐다.
실습) localhost:9090 접근, (p.241 참고)

프로메테우스를 통해 정보, 간단 쿼리, 상태별 컨테이너 수, 헬스 체크 횟수 등 다양한 정보를 제공한다.

## 9.2 애플리케이션의 측정값 출력하기
앱의 유용 정보를 측정 값으로 구성하려면, 좀 더 수고가 많이 필요하다.
- 정보 생성 코드 작성해 http 엔드포인트로 출력

주요 프로그래밍 언어는 프로메테우스 라이브러리 제공되므로 이를 그냥 사용하면 간편하다.
실습) p.244 참고
- cd ./ch09/exercises
- docker container rm -f $(docker container ls -aq)
- docker network create nat
- docker-compose up -d
  - localhost:8010/metrics (go)
  - localhost:8011/actuator/prometheus (java) 
  - localhost:8012/metrics (node)

실습) p.248 참고
- for i in {1..5}; do curl http://localhost:8010 > /dev/null; done
  - 반복문을 돌며 다섯 번의 http get 요청을 보낸다.

완독 후 설정에 대한 참고를 해보자.
1. 외부 시스템과의 통신 시간, 응답 성공 체크, 속도 이상에 영향을 주는 요청인지 체크
2. 로그 가치가 있는 모든 정보를 로그 보다 측정 값으로 수집하는 편이 메모리, 디스크 용량, CPU 성능 면에서 저렴하고 시각화에 용이하다.
3. 측정 값을 활용한 실시간 정보로 대시 보드 구성

## 9.3 측정값 수집을 맡을 프로메테우스 컨테이너 실행하기
프로메테우스는 직접 측정 값을 대상 시스템에 받아 수집하는 풀링 방식으로 동작한다.
측정 값을 수집하는 이 과정을 스크래핑이라고 한다.

프로메테우스 실행시 스크래핑 대상 엔드포인트를 설정해야 한다.
운영 환경 컨테이너 플랫폼에서는 클러스터에 있는 모든 컨테이너를 찾도록 설정할 수 있다.
도커 컴포즈 환경에서는 서비스 목록으로 도커 네트워크 DNS를 통해 대상 컨테이너를 자동으로 찾는다.
```yaml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: "image-gallery"
    metrics_path: /metrics
    static_configs:
      - targets: ["image-gallery"]
  - job_name: "iotd-api"
    metrics_path: /actuator/prometheus
    static_configs:
      - targets: ["iotd"]
  - job_name: "access-log"
    metrics_path: /metrics
    dns_sd_configs:
      - names:
        - accesslog
        type: A
        port: 80
```
- 정적 설정인 static_config는 호스트명으로 단일 컨테이너 지정
- dns_sd_config를 통해 DNS 서비스 디스커버리 기능을 통해 여러 컨테이너 지정
- 10초마다 한 번씩 모든 컨테이너 측정 값 수집

실습) p.254 참고
- docker-compose -f docker-compose-scale.yml up -d --scale accesslog=3
- for i in {1..10}; do curl http://localhost:8010 > /dev/null; done

accesslog 서비스는 세 개의 컨테이너가 동작 중이다.
이 세 개의 서비스에 대한 로드 밸런싱이 잘 적용 됐는지 어떻게 검증할까?

앱 컴포넌트에서 수집한 측정 값에는 컨테이너 호스트명도 포함된다.
프로메테우스 웹 인터페이스를 열어 access-log 컴포넌트 측정 값 살펴보자.
localhost:9090/graph - access_log_total 
해당 웹 UI를 통해 세 개의 컨테이너에 얼마나 고르게 요청이 분배됐는지 확인 가능하다.
이상적이라면 세 개 모두 고르게 value가 분배 됐겠지만, 
로드 밸런싱에 네트워크가 관여하는 부분(DNS 캐시, Http keep-alive 커넥션 등)이 많으므로,
단일 서버에서 도커 실행시 측정 값이 완전히 같기 어렵다.

실습) p.256 참고
- sum(access_log_total) without(hostname, instance)
  - 이 쿼리를 통해 합을 구할 수 있다.

## 9.4 측정값 시각화를 위한 그라파나 컨테이너 실행하기
어떤 측정 값을 수집할 것인지는 비즈니스 목표와 운영상 필요 여부에 따라 결정된다.

프로메테우스를 통해 데이터 수집, 데이터 시각화를 위한 쿼리 등을 활용하고,
이 쿼리를 연결해 대시보드를 구성하는 데 그라파나를 사용한다.

그라파나 대시보드는 앱의 핵심 정보를 다양한 수준에서 제공하고, 그래프 하나하나는 PromQL로 작성된 단일 쿼리로 그려진다.

실습) p.262 참고
- export HOST_IP=$(ip route get 1 | awk '{print $NF;exit}')
  - hostIP=$(ifconfig en0 | grep -e 'inet\s' | awk '{print $2}')
- docker-compose -f ./docker-compose-with-grafana.yml up -d --scale accesslog=3
- for i in {1..20}; do curl http://localhost:8010 > /dev/null; done
- localhost:3000 접근

대시보드의 구성이 구성하다면 구글 제공 문서인 [사이트 신뢰성 엔지니어링](http://mng.bz/EdZj) 참고
주로 지연 시간, 트래픽, 오류, 가용 시스템 자원을 주요 측정 값으로 지목하는데, 이를 합쳐 골든 시그널이라 한다.

대시보드의 그래프는 절대적인 값 보단 변화하는 추세에서 알 수 있는 정보가 많다.
앱 구동 평균 메모리가 얼마인지 중요하지 않다.
중요한 것은 평균 값에서 벗어나 수치가 튀어오르는 순간이 언제인지다.
컴포넌트의 측정 값을 조합해 이상 현상과 이들의 상관 관계를 찾아야 한다.

현대적인 앱에서 가장 널리쓰이는 그라파나는 그 자체로 배워둘 가치가 충분하다.
실습) p.268 참고
- add panel - add query
  - sum(image_gallery_requests_total{code="500"}) without(instance)

## 9.5 투명성의 수준
실제 서비스 가능 수준으로 나아가기 위해서 투명성은 반드시 필요하다.
도커의 매력은 컨테이너를 중심으로 만들어진 생태계와 이들 생태계를 구성하는 도구를 적용하는 패턴에 있다.

컨테이너 기술 초기 모니터링은 골치아팠다.
운영 환경에 투입된 앱 상태 파악이 너무 어려웠다.
시행착오를 겪으며 현대 앱에서는 신뢰성 있는 모니터링이 등장했다.

도커 엔진은 외부로 측정 값을 노출시키도록 설정한다. 
이를 통해 컨테이너, 호스트에 대한 인프라 정보를 얻을 수 있다.

컨테이너에서 실행 중인 애플리케이션은 생성한 측정 값을 노출하도록 엔드포인트를 만든다.
측정 값은 런타임 수준의 성능 정보와 앱 내부 상황에 대한 사용자 정의 측정 값이 있다.

도커 엔진은 애플리케이션을 지속적으로 풀링하여 측정 값을 얻는다.

프로메테우스는 도커 엔진 및 앱 컨테이너로부터 측정 값을 수집하도록 설정한다.
컨테이너 수나 도커 서버가 변경돼도 문제 없이 수집 가능하다.

그라파나는 프로메테우스의 측정 값을 토대로 핵심 값을 정리해서 대시보드를 구성하고 설정한다.
각 그래프마다 프로메테우스에 PromQL 쿼리로 질의한 결과다.

## 9.6 연습 문제
- p.274 참고
- docker rm -f $(docker ps | awk '{print $1}')
  - 현재 실행중 컨테이너가 모두 삭제

# 10장 도커 컴포즈를 이용한 여러 환경 구성
이식성은 도커의 가장 핵심이다.

## 10.1 도커 컴포즈로 여러 개의 애플리케이션 배포하기
도커 컴포즈는 여러 개의 컨테이너로 구성된 앱을 단일 도커 엔진 호스트에서 실행하기 위한 도구다.
개발 환경 또는 테스트 환경에서 주로 쓰이며, 앱의 버전을 달리해 서로 다른 환경에서 구동해야 할 때도 유용하다.
무턱대고 여러 컨테이너를 같은 포트를 써서 사용하면 안 된다.
무턱대고 여러 컨테이너가 공유 자원으로써 데이터를 쓰게 하는 것도 안 좋다.

실습) p.275 참고
- cd ./ch10/exercises
- docker-compose -f ./numbers/docker-compose.yml up -d
- docker-compose -f ./todo-list/docker-compose.yml up -d
- docker-compose -f ./todo-list/docker-compose.yml up -d

무작위 숫자 앱과 todo 앱 두 개 실행
todo 앱 두 번쨰를 실행하면 컨테이너가 생성되지 않는다.
이미 앱 컨테이너가 구동중인 것을 확인하고 실행하지 않는다.

도커 컴포즈는 도커 리소스가 어떤 앱의 일부인지 판단하기 위해 '프로젝트'라는 개념을 사용한다.
도커 컴포즈 파일이 들어있는 디렉터리명인데, 프로젝트명을 리소스 이름 접두사로 붙이고, 컨테이너 이름에는 번호를 접미사로 붙인다.
디렉토리가 한글인 경우 컨테이너가 실행되지 않는 경우가 있는데, 접두사로써 잘못됐기 때문이다. (영어 쓰기)
앱은 대게 여러 요소로 분할 돼 구성된다.

# 7장 도커 컴포즈로 분산 애플리케이션 실행하기
도커는 n-티어 모놀리식 설계부터 MSA 설계까지 분산 컴포넌트 관리에 이상적이다.

## 7.1 도커 컴포즈 파일의 구조
Dockerfile 스크립트는 애플리케이션을 패키징을 위한 스크립트다.
Dockerfile 스크립트 = App Packaging 스크립트

분산 앱은 단지 한 부분을 패키징하는 수단으로 보면 된다.
백 / 프론트로 나뉜 경우 두 개의 도커 파일이 필요하다.
백엔드가 MSA로 여러 도메인으로 분할 관리하는 경우, 다시 n개만큼 도커 파일이 필요하다.

직접 순서대로 여러 도커파일을 수동으로 옵션을 지정해 실행 할 수 있지만,
실수 가능성이 높아진다. 심지어 앱 동작의 문제가 생길 수 있다.
이런 경우 도커 컴포즈 파일에 앱 구조를 정의하면 된다.

컨테이너 실행시 지정할 모든 옵션과 도커 네트워크, 볼륨 등 도커 API에 명령을 내린다.

ex)
```dockerfile
verison: '3.7'

services:
    todo-web:
        image: diamol/ch06-todo-list
        ports:
            - "8020:80"
        networks:
            - apt-net
networks:
    app-net:
        external:
            name: nat
```
- 도커 컴포즈는 문법이 이해하기 쉽고, json 변환에 용이한 YAML 문법으로 기술된다.
- 예제상 세 개의 최상위 문으로 구성된다.
  1. version
    - 도커 컴포즈 파일 형식 버전
  2. services
    - 앱 구성 모든 컴포넌트 열거
    - 실제 컨테이너 대신 서비스 개념을 단위로 삼는다.
  3. networks
    - 서비스 컨테이너가 연결될 모든 도커 네트워크 열거
- diamol/ch06-todo-list 이미지를 통해 단일 컨테이너로 실행된다.
- 컨테이너의 80번 포트를 호스트 컴퓨터 8020번 포트를 통해 공개한다.
- app-net 정의된 app-net 도커 네트워크에 접속
- 서비스 이름은 컨테이너 이름이자 도커 네트워크상 다른 컨테이너가 식별할 수 있게 한다.
- 서비스 구성 네트워크는 app-net
- app-net 네트워크는 net이라는 외부 네트워크로 연결된다.
- external 의미는 nat 네트워크는 이미 존재하므로, 새로 생성하지말라는 것이다.
  - 여기에 설정된 네트워크가 존재하지 않는 경우 도커 네트워크를 생성한다.


도커 컴포즈는 도커 명령과는 다르게, 앱 실행을 위해 up 명령을 실행해야 한다.
up을 통해 컴포즈 파일 체크, 정의된 상태로 실행하기 위해 필요 요소 준비를 시작

실습) 도커 네트워크 생성, 예제를 받은 후 도커 컴포즈 실행해보기
- docker network create nat
- cd ./ch07/exercises/todo-list
- docker-compose up

docker-compose up 실행시 현재 작업 디렉토리에서 docker-compose.yml 파일을 찾는다.
그리고 서비스들을 읽어들이고, 설정한 이미지를 내려 받고, 컨테이너를 실행하고, 컨테이너는 정의된대로 동작한다.
또한 간접적으로 문서화 효과를 얻을 수 있다.
단일 서비스라면 몰라도 여러 서비스로 구성된 도커 컨테이너는 도커 컴포즈 파일이 꼭 필요하다.

## 7.2 도커 컴포즈를 사용해 여러 컨테이너로 구성된 애플리케이션 실행하기
도커 컴포즈를 통해 여러 서비스의 환경 변수, 명령 등을 정의하고, 서비스 간 통신을 자유롭게 할 수 있다.

```yaml
accesslog:
  image: diamol/ch04-access-log

iotd:
  image: diamol/ch04-image-of-the-day
  ports:
    - "80"
      
image-gallery:
  image: diamol/ch04-image-gallery
  ports:
    - "8010:80"
  depends on:
    - accesslog
    - iotd

# 네트워크 부분 생략
```
- accesslog는 공개 ports도 없이 이미지만 입력됐다.
- iotd는 rest api로, 80번 포트를 외부 무작위 포트를 통해 공개
- image-gallery도 외부 포트 공개, 다른 두 서비스에 의존한다는 것을 입력
  - 의존성 코드를 통해 나열된 두 서비스를 먼저 실행하려고 한다.

도커 컴포즈를 통해 분리 모드로 앱 실행해보자.
도커 컴포즈는 컨테이너 로그를 수집하지만, 컨테이너는 백그라운드로 동작한다.
따라서 컴포즈의 기능을 사용해볼 수 있다.
실습) 예제 앱 실행해보기
- cd ./ch07/exercises/image-of-the-day
- docker-compose up --detach
  - --detach 명령을 통해 컨테이너가 백그라운드로 실행되어, 명령 실행창에 로그 출력이 없다.
    실습) 도커 컴포즈를 사용해 iotd 서비스 컨테이너 수 늘리고, iotd 컨테이너 로그 살펴보기
- docker-compose up -d --scale iotd=3
- docker-compose logs --tail=1 iotd
  - --tail1=1 파라미터는 iotd 컨테이너의 마지막 로그를 출력하라는 의미다.

iotd 서비스 컨테이너를 총 세개로 관리하고, 해당 서비스에 api 요청시 세 개의 컨테이너에 고르게 분배해준다.
logs를 활용해 스케일링된 세 개의 컨테이너에 요청이 왔는지 체크 할 수 있다.

이처럼 도커 컴포즈가 대신 컨테이너들을 관리해준다.
하지만 도커 컴포즈를 통해 전체 앱을 관리할 수 있지만,
컴퓨팅 자원 절약을 위해 컨테이너 중지, 재시작, 재가동 등의 작업은 도커 명령행을 통해 할 수 있는 작업이다.
도커 컴포즈를 통해 컨테이너 관리를 돕지만, 내부적으로는 마찬가지로 도커 API를 사용한다.
따라서 도커 컴포즈를 통해 실행한 컨테이너도 도커 명령으로 관리 가능하다.
실습) 앱 중지, 재시작 후 실행 중인 컨테이너 목록 출력
- docker-compose stop
  - 중지된 모든 컨테이너는 CPU, 메모리를 점유하지 않지만, 컨테이너의 파일 시스템은 유지한다.
- docker-compose start
  - up과 start의 차이점 알기
  - 다시 앱 시작시 기존에 생성되었던 컨테이너가 재시작
- docker container ls

- docker-compose
  - docker-compose --help와 마찬가지로, 전체 부명령 목록 체크 가능

도커 컴포즈는 클라이언트 측에서 동작하는 도구다.
도커 컴포즈 명령에 따라 도커 API로 지시를 보낸다.

도커 엔진 자체는 컨테이너를 실행할 뿐, 여러 컨테이너가 어떤 앱에서 동작하는지 여부는 알 수 없다.
따라서 도커 컴포즈를 통해 파일 작성 후 도커 엔진이 이 파일을 읽을 수 있게 해야 한다.

컴포즈 파일 수정 또는 도커 명령을 통해 앱 수정시 앱과 불일치 할 수 있다.
불일치 상태에서 비정상적인 동작을 보일 수 있다.
실습) 도커 컴포즈를 통해 앱 재시작하고 스케일링 상태 확인해봐라, 3개인지 체크
- docker-compose down
  - 앱 제거 명령, 앱 중지되고, 컨테이너 모두 제거된다. external 플래그가 없다면 볼륨과 네트워크도 제거 대상
- docker-compose up -d
- docker container ls

도커 컴포즈는 사용하기 쉽고, 강력한 기능을 갖췄다.
하지만 yaml의 컴포즈 파일 정의에 의존하는 클라이언트 측 도구임을 잊지말자.

도커 컴포즈로 앱 배포시 다양한 리소스가 생성되지만, 도커 엔진은 단순히 컨테이너를 실행할 뿐이다.
리소스 관리는 컴포트 파일을 통해 관리하자.

## 7.3 도커 컨테이너 간의 통신
분산 앱의 모든 구성 요소는 컴포즈를 통해 관리되고 컨테이너로 실행된다.

그렇다면 컨테이너간 통신은 어떻게 할까?
컨테이너는 별도 네트웤 공간을 가진 가상 환경이다.
도커 엔진으로부터 부여받은 가상 IP 주소를 가지며, 도커 네트워크로 연결하여 가상 IP를 통해 통신할 수 있다.
그러나 컨테이너 교체시 가상 IP 주소도 변경된다.
변경돼도 통신을 유지할 수 있도록 도커에 내장된 DNS 서비스를 이용해 서비스 디스커버리 기능을 제공한다.

DNS는 인터넷과 사설 네트워크 모두 동작한다.
컴퓨터는 IP를 알아내 실질적으로 통신을 수행하지만, 사람에게 친숙한 것은 도메인이다.
IP는 주소가 변경될 수 있고, 외우기 쉽지 않기 때문이다.

도커 내장 DNS 서비스를 통해 컨테이너의 가상 IP를 찾아준다.
이를 통해 같은 도커 네트워크에 있는 다른 컨테이너 정보를 사용 가능하다.
도메인의 대상이 IP가 아니라면, 호스트 컴퓨터의 네트워크나 인터넷 IP 주소를 조회한다. (?)
실습) 도커 컴포즈를 통해 iotd 컨테이너를 스케일업해서 실행 후 컨테이너에서 DNS 조회 명령 실행
- docker-compose up -d scale --iotd=3 (?)
  - docker-compose up -d --scale iotd=3
- docker container exec -it image-of-the-day_image-gallery_1 sh
  - nslookup accesslog
    - 웹 앱 컨테이너 기반 이미지의 유틸리티, 명령 인자로 도메인 지정시 해당 도메인 DNS 서비스 조회, 결과 출력
  - exit

도커 네트워크에 연결된 모든 컨테이너는 이 네트워크 범위에 포함되는 가상 IP 주소를 부여받는다.
해당 네트워크를 통해 컨테이너간 통신이 가능하다.
DNS 조회를 사용하면, 컨테이너 교체로 IP 주소가 변경돼도 컨테이너에 접근 가능하다.
실습) 도커 명령으로 accesslog 컨테이너 삭제, 도커 컴포즈 재 실행, 웹 컨테이너 셸 실행 후 DNS 재 조회
- docker container rm -f image-of-the-day_accesslog_1
- docker-compose up -d --sacle iotd=3
- docker container exec -it image-of-the-day_image-gallery_1 sh
  - nslookup accesslog
  - nslookup iotd
  - exit

삭제되고 새로 생성된 컨테이너는 도커 엔진으로부터 가상 IP를 새로 부여받는다.
또한 iotd와 같이 하나의 도메인에 dns 조회시 각 컨테이너를 가리키는 세 개의 가상 ip주소가 출력된다.
도커 컴포즈는 이 점을 활용해 간단 로드 밸런싱 구현 가능하다.
여러 개 IP 주소를 어떻게 활용할지는 전적으로 애플리케이션이 결정한다.
간단한 조회는 첫 번 째 IP만 사용하게 할 수 있고, 모든 컨테이너에 고르게 분배할 수도 있다.
도커 DNS 시스템은 조회 결과의 순서를 매번 변화시킨다.
nslookup을 활용해 컨테이너간 트래픽 고르게 분산 가능하다.

도커 컴포즈는 컨테이너 실행시 지정된 모든 옵션 값을 기억하고, 옵션 값을 통해 컨테이너간 통신을 처리한다.
네트워크에 포함된 가상 IP 범위가 있고,
컨테이너 삭제시 해당 가상 IP는 재사용 가능 상태가 된다.
따라서 컨테이너 삭제 후 생성해도, 같은 IP를 우연하게 사용 가능하다.

## 7.4 도커 컴포즈로 애플리케이션 설정값 지정하기
앱 컨테이너를 단일로 실행하고, 데이터는 SQLite 데이터베이스에 저장한다면?
이 경우 컨테이너 안 파일 하나만 있으면 된다.

그러나 소규모 프로젝트가 아닌 경우는 SQLite는 애매하다.
PostgreSQL을 사용해보도록 하자.
앱 컨테이너와 데이터베이스 컨테이너를 따로 실행해 분산 앱으로 구동 할 수 있다.
도커 컴포즈를 사용해 설정 값 적용해보자.

```yaml
services:
  todo-db:
    image: diamol/postgres:11.5
    ports:
      - "5433:5432"
    networks:
      - app-net
  todo-web:
    image: diamol/ch06-todo-list
    ports:
      - "8020:80"
    environment:
      - Database: Provider=Postgres
    depends_on:
      - todo-db
    networks:
      - app-net
    secrets:
      - source: postgres-connection
        target: /app/config/secrets.json
```
- environment: 컨테이너 안 사용될 환경 변수 값 정의
- secrets: 실행시 컨테이너 내부 파일에 기록될 비밀 값 정의, target에 정의된 파일이 생기고, source 값이 비밀 값의 값이 기록된다.

비밀 값은 주로 클러스터 환경에서 컨테이너 플랫폼을 통해 제공된다 (쿠버, 도커 스웜, ...)
평소에는 클러스터 데이터베이스에 암호화되어 있고 패스워드, 인증서, API 키 등 민감한 정보로 구성된 설정 값 전달에 적합하다.

```yaml
secrets:
  postgres-connection:
    file: ./config/secrets.json
```
- 비밀 값 postgres-connection의 값을 ./config/secrets.json 파일에서 읽어오라는 의미다.
- 호스트 컴의 파일이 컨테이너에 영향을 미친다는 점에서 바인드 마운트와 비슷하다.
  - 추후 클러스트 환경에서 암호화된 진짜 비밀 값으로 이전 여지를 남겨둔 것

앱의 설정 값을 컴포즈 파일에 정의시 이미지를 다양하게 활용 할 수 있다.
실습) 예제 도커 컴포즈 업 하기
- cd ./ch07/exercises/todo-list-postgres
- docker-compose up -d
- docker-compose ps
  - 컴포즈 파일에 정의된 모든 컨테이너 목록을 보여준다.

패키징된 앱과 설정 값을 분리할 수 있는 것이 도커의 핵심 장점 중 하나다.
앱 이미지는 빌드 파이프 라인을 통해 만들어지고 테스트 환경을 거쳐 운영 환경 적합한지 검증된다.

## 7.5 도커 컴포즈도 만능은 아니다.
도커 컨테이너의 본격적 사용을 위해 도커 컴포즈는 매우 중요한 도구다.
도커 컴포즈는 도커 스웜이나 쿠버네티스 같은 완전한 컨테이너 플랫폼은 아니다.
즉 앱이 지속적으로 정의된 상태를 유지하도록 하는 기능은 없다.
일부 컨테이너가 오류 또는 종료가 돼도 docker-compose up 명령을 다시 실행하지 않는 한 앱의 상태를 되돌릴 수 없다.

운영 환경에서는 도커 컴포즈보단, 도커 스웜이나 쿠버네티스가 쓰인다.
그러나 앱 정의에는 컴포즈파일 포맷을 사용한다.

도커 컴포즈가 모든 운영 환경에서 부적합하다는 것은 아니다.
컨테이너 클러스터의 운영 계획이 없는 한 도커 컴포즈로도 충분하다.

## 7.6 연습 문제

# 8장 헬스 체크와 디펜던시 체크로 애플리케이션의 신뢰성 확보하기
실행중인 컨테이너 앱을 운영 환경에 맞게 다듬을 수 있다.
도커 스웜이나 쿠버네티스 등과 같은 컨테이너 플랫폼을 통해 자동으로 에러에서 회복 할 수 있는 기능을 제공한다.
실행 중인 컨테이너의 앱이 상태가 정상인지 체크하는 정보가 이미지와 함께 패키징 되어 있다.
이를 통해 비정상 컨테이너 삭제 후 새 컨테이너로 대체한다.

## 8.1 헬스 체크를 지원하는 도커 이미지 빌드하기
도커는 컨테이너 시작 시점에 앱의 기본 상태를 확인한다.
컨테이너 실행시 앱 실행 파일이나 특정한 프로세스가 실행되는데, 도커는 이 프로세스의 실행 상태를 확인한다.
만약 종료되었다면, 컨테이너도 함께 종료된다.
이를 통해 기본적인 헬스 체크를 한다.

클러스터 환경에서 종료된 컨테이너를 재시작하거나 새 컨테이너로 교체하는 작업을 대신 해 준다.
그러나 오류를 맞이한 동일한 상황이 오면 또 컨테이너는 재시작하거나 교체하는 작업이 필요해진다.
앱의 동작이 멈춰도 도커는 컨테이너를 정상이라 판단한다.

도커는 앱의 상태가 실제 정상인지 확인하는 정보를 직접 넣을 수 있는 똘똘한 기능을 제공한다.
Dockerfile 스크립트에 상태 확인 로직을 추가하면 된다.

먼저, 헬스 체크 로직이 없는 상태에 생길 수 있는 문제 먼저 체험해보자.
실습) 예제 앱 실행, 비정상 상태 유도, ...
1. docker container run -d -p 8080:80 diamol/ch08-numbers-api
  - API 컨테이너 실행
2. API 세 번 호출
  - curl http://localhost:8080/rng
  - curl http://localhost:8080/rng
  - curl http://localhost:8080/rng
  - curl http://localhost:8080/rng
    - 네 번 째 호출에서 실패
    - 그러나 도커 컨테이너는 실행중

Dockerfile의 HEALTHCHECK 인스트럭션 사용해보기
컨테이너 런타임은 이 정보를 이용해 동작중인 앱의 상태가 정상인지 체크 가능하다.
이 인스트럭션을 통해 도커가 컨테이너 안에서 실행하는 명령어 지정 가능하다.
이 명령의 반환 상태 코드를 보고 앱의 상태를 판단한다.
앱 상태 판단 가능한 어떤 명령을 지정해도 무방하다.

도커는 컨테이너 안에서 주기적으로 지정된 명령을 실행한다.
이를 통해 일정 횟수 실패시 컨테이너를 이상 상태로 간주한다.

```dockerfile
FROM diamol/dotnet-aspnet

ENTRYPOINT ["dotnet", "/app/Numbers.Api.dll"]
HEALTHCHECK CMD curl --fail http://localhost/health

WORKDIR /app
COPY --from=builder /out/ .
```
- 위에 실습과 다른 점은 API 호출이 컨테이너 내부에서 실행된다는 점이다.
- 헬스 체크시 엔드포인트 /health로 http 요청을 보낸다.
- --fail 옵션 사용시 curl이 전달받은 상태 코드를 도커에 전달한다. (성공: 0, 실패: 0 외에 다른 숫자)

Dockerfile 스크립트의 파일명이나 경로가 다른 경우 부 명령을 이용하면 된다.
실습) 터미널로 최상위 디렉토리 이동, 다른 경로 도커파일 태그 부여해 이미지 빌드
- cd ./ch08/exercises/numbers
  - 최상위 디렉토리 이동
- docker image build -t diamol/ch08-numbers-api:v2 -f ./numbers-api/Dockerfile.v2 .

헬스 체크 간격과 누적 실패 횟수도 설정 가능하다.
기본 값은 30초 간격 연속 3회 실패시 앱을 이상 상태로 간주한다.

실습) 다시 실행해보기
- docker container run --rm -d -p 8081:80 diamol/ch08-numbers-api:v2
- docker container ls
- curl http://localhost:8081/rng
- curl http://localhost:8081/rng
- curl http://localhost:8081/rng
- curl http://localhost:8081/rng
  - api 실패 유발
- docker container ls
  - 이상 상태 감지 체크
  - 90초 지나고 health 상태에서 unhealth가 된다.

컨테이너 이상 상태는 도커 API를 통해 보고된다.
따라서 애플리케이션 내에 오류가 존재하지만, 컨테이너가 실행중일 때도 복구를 위한 조치 가능하다.
뿐만 아니라 가장 최근 헬스 체크 수행 결과도 저장돼 있어 확인 가능하다.
docker container inspect 명령을 통해 확인 가능하다.

실습) 가장 최근 만든 컨테이너 상태 출력
- docker container inspect $(docker container ls --last 1 --format '{{.ID}}')
  - State 필드 확인

그러나 컨테이너 상태를 확인하면 컨테이너는 여전히 실행 중 상태다.
컨테이너 재시작 또는 새 컨테이너로 교체는 어떻게 할까?

도커는 이런 작업을 안전하게 처리할 순 없다.
재시작하면 애플리케이션은 완료될 때 까지 동작하지 않는다.
그 사이의 데이터 유실 될 수 있고 상황이 더 악화될 수 있다.
따라서 컨테이너를 그대로 두는 것이 최선이다.
또한 일시적인 unhealth는 컨테이너 상태는 다시 health 해진다.
도커 스웜이나 쿠버네티스 같은 클러스터 환경에서는 헬스 체크 기능이 더욱 유용하다.
헬스 체크를 통해 컨테이너 이상 상태 통보를 통해 자동 조치 가능한 덕분이다.
클러스터는 컨테이너 추가 실행 여력이 충분하기에 잘 활용될 수 있다.
즉 이상 상태 컨테이너를 두고, 대체 컨테이너를 실행해 앱의 중단 시간 없이 상태 회복 가능하다.

## 8.2 디펜던시 체크가 적용된 컨테이너 실행하기
여러 컨테이너에 나뉘어 실행되는 분산 앱은 또 하나의 문제를 겪을 수 있다.
컨테이너 교체시 컨테이너간 의존 관계를 고려하지 않는다.
동작하는 서버가 한 대라면, 특정 서버 먼저 실행되도록 보장할 수 있지만,
클러스터 환경의 컨테이너 플랫폼은 컨테이너의 실행 순서까지 통제할 수 없다.
그래서 선 실행 되어야 할 컨테이너가 후 실행 되는 상황이 올 수 있다.

실습) 실행 중 모든 컨테이너 제거, 시키는대로 해보기 (서적 참고)
- docker container rm -f $(docker container ls -aq)
- docker container run -d -p 8082:80 diamol/ch08-numbers-web
- docker container ls

제대로 동작해보이지만, 내부 연관된 컨테이너가 동작되지 않아 에러가 발생한다.
컨테이너는 정상이지만, 애플리케이션간 의존관계를 만족하지 않아 비정상 동작을 유발하게 된다.
애플리케이션 중 필요 의존 관계 미리 체크하는 로직을 넣는 것이 가능한 앱도 있다.

의존관계 만족하는지 점검하는 디펜던시 체크 기능도 도커 이미지에 추가할 수 있다.
앱 실행 전 필요 요구사항 확인하는 기능으로 모든 요구 사항 확인 후 디펜던시 체크 성공하면 앱이 실행된다.

디펜던시 체크는 별도의 인스트럭션을 갖고 있진 않고, 애플리케이션 실행 명령을 통해 로직을 추가해야 한다.
CMD 인스트럭션을 통해 앱 실행 전 API 사용 가능 여부 체크
```dockerfile
FROM diamol/dotnet-aspnet

ENV RngApi:Url=http://numbers-api/rng

CMD curl --fail http://numbers-api/rng && dotnet Numbers.web.dll

WORKDIR /app
COPY --from=builder /out/ .
```
- API 사용 가능 여부 체크를 위해 기반 이미지에 포함된 유틸리티 curl를 활용
- CMD 인스트럭션에 정의된 명령은 컨테이너 실행할 때 실행된다.
  - and 조건으로 두 조건이 모두 성공시 실행된다.
  - 하나라도 실패시 컨테이너는 그대로 종료된다.

실습) 서적에서 시키는대로 하기 (p.215)
- docker container run -d -p 8084:80 diamol/ch08-numbers-web:v2
- docker container ls -all

CMD를 통해 의존관계 컨테이너가 실행되어 있지 않아서 컨테이너는 실행되지 않는다.
직관적이지 않지만, 이 상황에서는 컨테이너가 실행되지 않는 것이 그나마 괜찮다.

헬스 체크와 디펜던시 체크를 통해 컨테이너 플랫폼 환경에 적합한 앱이라고 판단하면 된다.
디펜던시 체크에 사용된 것은 CMD 인스트럭션의 curl로, 가장 기본적인 http 요청 테스트다.
단순한 방식으로 체크가 보장된다면 별도의 외부 도구는 필요하지 않다.

## 8.3 애플리케이션 체크를 위한 커스텀 유틸리티 만들기
curl는 웹앱 또는 API 테스트시 매우 유용한 도구다.
하지만 실무에서 앱 테스트 목적으로 curl를 사용하진 않는다.
보안 정책상 도커 이미지에 curl를 포함시킬 수 없다.

도커 이미지에는 앱 구동을 위해 필요한 최소 내용만 가져야 한다.
curl는 컨테이너 상태 체크에 유용한 도구이지만, 현업에서는 프로그래밍 언어로 구현된 별도 커스텀 유틸리티를 사용하는 것이 좋다.

- 프로그래밍 언어로 구현된 커스텀 유틸리티 장점
  1. 이미지에 추가적인 소프트웨어를 포함시킬 필요 없다.
  2. 조금 더 구체적인, 예를 들면 재시도 횟수, 분기 등 복잡한 체크 로직 적용 가능
  3. URL 여러 곳 정의되거나, 수정시 누락 방지 가능
  4. 컨테이너 실행 전 체크가 필요한 모든 사항 검증 가능

다양한 상황에서도 동작 가능한 장점으로, curl 보단 애플리케이션 언어로 디펜던시 체크 등 컨테이너 상태를 체크하자.

```dockerfile
FROM diamol/dotnet-aspnet

ENTRYPOINT ["dotent", "Numbers.Api.dll"]
HEALTHCHECK CMD ["dotnet", "Utilities.HttpCheck.dll", "-u", "http://localhost/health"]

WORKDIR /app
COPY --from=http-check-builder /out/ .
COPY --from=builder /out/ .
```

실습) 책에서 시키는대로.. (p.219)
- docker container rm -f $(docker contaoner ls -aq)
  - 기존 컨테이너 모두 삭제
- docker container run -d -p 8080:80 --health-interval 5s diamol/ch08-numbers-api:v3
  - 헬스 체크 간격 5초로 설정, 기본 15초
- docker container ls
- curl http://localhost:8080/rng
- curl http://localhost:8080/rng
- curl http://localhost:8080/rng
- curl http://localhost:8080/rng
  - 실패 유발
- docker container ls
  - 15초 후 이상 상태 변경 체크

헬스 체크를 닷넷으로 구현된 Http 테스트 유틸리티를 사용하면서 다양한 상황에 대응에 유연하다.
디펜던시 체크도 마찬가지로 같은 유틸리티 사용했다.

```dockerfile
FROM diamol/dotnet-aspnet

ENV RngApi:Url=http://numbers-api/rng
CMD dotnet Utilities.HttpCheck.dll -c RngApi:Url -t 900 && dotent Numbers.Web.dll

WORKDIR /app
COPY --from=http-check-builder /out/ .
COPY --from=builder /out .
```
- 이미지에 curl 제거하고, 헬스 체크와 디펜던시 체크를 유지했다.

실습) 책에서 시키는대로.. (p.221)
- docker container run -d -p 8081:80 diamol/ch08-numbers-web:v3
- docker container ls --all

커스텀 테스트 유틸리티를 통해 이미지 이식성이 향상된다.
컨테이너 플랫폼마다 헬스 체크와 디펜던시 체크를 정의하고 실행하는 방법에는 차이가 있다.
그러나 커스텀 테스트 유틸리티를 통해 어떤 환경에서도 그대로 동작 가능하다.

## 8.4 도커 컴포즈에 헬스 체크와 디펜던시 체크 정의하기
도커 컴포즈는 앱 상태 이상시 어느 정도 복원 가능한 기능이 있다.
그러나 새 컨테이너로 대체하진 않는다.
종료된 컨테이너를 재시작하거나, 이미지에 정의되지 않은 헬스 체크 추가 가능하다.

```yaml
numbers-api:
  image: diamol/ch-numbers-api:v3
  ports:
    - "8087:80"
  healthcheck:
    interval: 5s
    timeout: 1s
    retries: 2
    start_period: 5s
  networks:
    - app-net
```
- 도커 컴포즈는 헬스 체크 옵션 더 상세하게 설정 가능
- interval: 헬스 체크 간격
- timeout: 제한 시간, 응답받지 못하면 실패로 간주
- retries: 실패 횟수, 채우면 이상 상태로 된다.
- start_period: 컨테이너 실행 후 첫 헬스 체크 실시 간격

헬스 체크 실시할 때 CPU와 메모리 자원이 필요하므로, 운영 환경에서는 좀 더 너프하게 잡으면 된다.
이미지에 헬스 체크를 안 하는 경우, 애플리케이션 언어와 도커 컴포즈를 통해 정의하는 방법이 있다.

```yaml
numbers-web:
  image: diamol/ch08-numbers-web:v3
  restart: on-failure
  ports:
    - "8088:80"
  healthcheck:
    test: ["CMD", "dotnet", "Utilities.HttpCheck.dll", "-t", "150"]
    interval: 5s
    timeout: 1s 
    retries: 2  
    start_period: 10s
  networks:
    - app-net
```
모든 컨테이너에 헬스 체크 적용 뿐 아니라, 이미지에 디펜던시 체크 포함돼 있다.
restart: on-failure를 통해 얘기치 않은 종료시 컨테이너를 재시작한다.
그러나 의존 관계 정의한 depends_on 설정이 없으므로, 컨테이너 실행 순서가 정의되지 않았다.

실습) 책에서 시키는대로.. (p.226)
- cd ./ch08/exercises/numbers
- docker container rm -f $(docker container ls -aq)
- docker-compose up -d
- docker container ls
- docker container logs numbers_numbers-web_1

도커 컴포즈를 내의 depends_on을 통해 디펜던시 체크를 직접 하지 않는 이유는,
도커 컴포즈가 디펜던시 체크 가능 범위가 단일 서버로 제한되어 있다.
운영 환경은 예측이 어렵기 때문에, depends_on 보단 프로그래밍 언어 테스트 유틸리티를 활용하자.

## 8.5 헬스 체크와 디펜던시 체크로 복원력 있는 애플리케이션을 만들 수 있는 이유
분산 시스템 앱은 유연성과 기민성이 뛰어나다.
그러나 그만큼 관리가 어렵다.

분산 시스템의 의존 관계 컨테이너가 너무 많다면 어떡할까?
디펜던시 체크와 헬스 체크 활약이 바로 이 지점이다.
두 체크를 도입하여 플랫폼 실행 순서를 보장할 필요 없다.
가능한 빨리 컨테이너를 실행하면 된다.
일부 컨테이너 의존 관계 만족되지 않으면 해당 컨테이너는 재실행 또는 새 컨테이너로 교체된다.

컨테이너가 재실행되고, 교체될 순 있어도 애플리케이션은 빠르게 계속 동작 가능하다.
앱 가동시 생애주기로, 오류 발생으로 헬스 체크가 연속으로 실패하면 새로운 컨테이너를 만들어 실행 후 기존 컨테이너를 종료한다.

하지만 헬스 체크와 디펜던시 체크는 주의가 필요하다. 즉 시스템 부하를 일으키면 안 된다.
따라서 애플리케이션이 실제 동작 중인이 검증하는 핵심만 최소한으로 테스트 돼야 한다.
디펜던시 체크는 앱 시작 시점에만 실행되므로, 너무 크게 신경 쓸 필요는 없다.

## 8.6 연습 문제

# 9장 컨테이너 모니터링으로 투명성 있는 애플리케이션 만들기
앱의 자동 스케일링 기능은 트래픽 부하에 적절하게 규모를 조절하고, 간헐적 오류에 스스로 복원 가능하다.
헬스 체크 기능만 사용해도 상당히 유용하다.

그래도 지속적인 모니터링과 이상 증후에 대한 통보 기능은 필요하다.
프로메테우스를 사용해 앱 컨테이너의 측정 수치를 수집하고,
그라파나를 사용해 수치를 시각화해 대시보드 형태로 구성한다.

## 9.1 컨테이너화된 애플리케이션에서 사용되는 모니터링 기술 스택
프로메테우스 역시 컨테이너에서 동작한다.
따라서 분산된 앱 컨테이너를 어렵지 않게 모니터링 가능하다.
도커 엔진과 컨테이너들로부터 데이터 수집하고 외부 공개 API를 포함해 컨테이너를 만든다.

도커 엔진 설정에서 프로메테우스 측정 기능을 명시적 활성화해야 한다.
도커 데스크탑을 활용해 daemon.json 파일 수정
실습) daemon.json 설정 값 추가
- "metrics-addr" : "0.0.0.0:9323"
- "experimental" : true

9323 포트를 통해 측정 값이 공개된다.
도커 엔진 설정 파일 변경만 해도,
localhost:9323/metrics를 통해 상태 정보가 프로메테우스 포맷으로 제공된다.

실습) p.240 책에 적힌대로
- hostIP=$(ifconfig en0 | grep -e 'inet\s' | awk '{print $2}')
- docker container run -e DOCKER_HOST=$hostIP -d -p 9090:9090 diamol/prometheus:2.13.1
  - 호스트 컴퓨터와 통신하고, 도커 엔진 상태 측정 값 수집

주기적으로 도커 호스트에서 측정 값 수집 후 디비에 저장하고, 이를 조회 가능한 웹 인터페이스가 실행됐다.
실습) localhost:9090 접근, (p.241 참고)

프로메테우스를 통해 정보, 간단 쿼리, 상태별 컨테이너 수, 헬스 체크 횟수 등 다양한 정보를 제공한다.

## 9.2 애플리케이션의 측정값 출력하기
앱의 유용 정보를 측정 값으로 구성하려면, 좀 더 수고가 많이 필요하다.
- 정보 생성 코드 작성해 http 엔드포인트로 출력

주요 프로그래밍 언어는 프로메테우스 라이브러리 제공되므로 이를 그냥 사용하면 간편하다.
실습) p.244 참고
- cd ./ch09/exercises
- docker container rm -f $(docker container ls -aq)
- docker network create nat
- docker-compose up -d
  - localhost:8010/metrics (go)
  - localhost:8011/actuator/prometheus (java)
  - localhost:8012/metrics (node)

실습) p.248 참고
- for i in {1..5}; do curl http://localhost:8010 > /dev/null; done
  - 반복문을 돌며 다섯 번의 http get 요청을 보낸다.

완독 후 설정에 대한 참고를 해보자.
1. 외부 시스템과의 통신 시간, 응답 성공 체크, 속도 이상에 영향을 주는 요청인지 체크
2. 로그 가치가 있는 모든 정보를 로그 보다 측정 값으로 수집하는 편이 메모리, 디스크 용량, CPU 성능 면에서 저렴하고 시각화에 용이하다.
3. 측정 값을 활용한 실시간 정보로 대시 보드 구성

## 9.3 측정값 수집을 맡을 프로메테우스 컨테이너 실행하기
프로메테우스는 직접 측정 값을 대상 시스템에 받아 수집하는 풀링 방식으로 동작한다.
측정 값을 수집하는 이 과정을 스크래핑이라고 한다.

프로메테우스 실행시 스크래핑 대상 엔드포인트를 설정해야 한다.
운영 환경 컨테이너 플랫폼에서는 클러스터에 있는 모든 컨테이너를 찾도록 설정할 수 있다.
도커 컴포즈 환경에서는 서비스 목록으로 도커 네트워크 DNS를 통해 대상 컨테이너를 자동으로 찾는다.
```yaml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: "image-gallery"
    metrics_path: /metrics
    static_configs:
      - targets: ["image-gallery"]
  - job_name: "iotd-api"
    metrics_path: /actuator/prometheus
    static_configs:
      - targets: ["iotd"]
  - job_name: "access-log"
    metrics_path: /metrics
    dns_sd_configs:
      - names:
        - accesslog
        type: A
        port: 80
```
- 정적 설정인 static_config는 호스트명으로 단일 컨테이너 지정
- dns_sd_config를 통해 DNS 서비스 디스커버리 기능을 통해 여러 컨테이너 지정
- 10초마다 한 번씩 모든 컨테이너 측정 값 수집

실습) p.254 참고
- docker-compose -f docker-compose-scale.yml up -d --scale accesslog=3
- for i in {1..10}; do curl http://localhost:8010 > /dev/null; done

accesslog 서비스는 세 개의 컨테이너가 동작 중이다.
이 세 개의 서비스에 대한 로드 밸런싱이 잘 적용 됐는지 어떻게 검증할까?

앱 컴포넌트에서 수집한 측정 값에는 컨테이너 호스트명도 포함된다.
프로메테우스 웹 인터페이스를 열어 access-log 컴포넌트 측정 값 살펴보자.
localhost:9090/graph - access_log_total
해당 웹 UI를 통해 세 개의 컨테이너에 얼마나 고르게 요청이 분배됐는지 확인 가능하다.
이상적이라면 세 개 모두 고르게 value가 분배 됐겠지만,
로드 밸런싱에 네트워크가 관여하는 부분(DNS 캐시, Http keep-alive 커넥션 등)이 많으므로,
단일 서버에서 도커 실행시 측정 값이 완전히 같기 어렵다.

실습) p.256 참고
- sum(access_log_total) without(hostname, instance)
  - 이 쿼리를 통해 합을 구할 수 있다.

## 9.4 측정값 시각화를 위한 그라파나 컨테이너 실행하기
어떤 측정 값을 수집할 것인지는 비즈니스 목표와 운영상 필요 여부에 따라 결정된다.

프로메테우스를 통해 데이터 수집, 데이터 시각화를 위한 쿼리 등을 활용하고,
이 쿼리를 연결해 대시보드를 구성하는 데 그라파나를 사용한다.

그라파나 대시보드는 앱의 핵심 정보를 다양한 수준에서 제공하고, 그래프 하나하나는 PromQL로 작성된 단일 쿼리로 그려진다.

실습) p.262 참고
- export HOST_IP=$(ip route get 1 | awk '{print $NF;exit}')
  - hostIP=$(ifconfig en0 | grep -e 'inet\s' | awk '{print $2}')
- docker-compose -f ./docker-compose-with-grafana.yml up -d --scale accesslog=3
- for i in {1..20}; do curl http://localhost:8010 > /dev/null; done
- localhost:3000 접근

대시보드의 구성이 구성하다면 구글 제공 문서인 [사이트 신뢰성 엔지니어링](http://mng.bz/EdZj) 참고
주로 지연 시간, 트래픽, 오류, 가용 시스템 자원을 주요 측정 값으로 지목하는데, 이를 합쳐 골든 시그널이라 한다.

대시보드의 그래프는 절대적인 값 보단 변화하는 추세에서 알 수 있는 정보가 많다.
앱 구동 평균 메모리가 얼마인지 중요하지 않다.
중요한 것은 평균 값에서 벗어나 수치가 튀어오르는 순간이 언제인지다.
컴포넌트의 측정 값을 조합해 이상 현상과 이들의 상관 관계를 찾아야 한다.

현대적인 앱에서 가장 널리쓰이는 그라파나는 그 자체로 배워둘 가치가 충분하다.
실습) p.268 참고
- add panel - add query
  - sum(image_gallery_requests_total{code="500"}) without(instance)

## 9.5 투명성의 수준
실제 서비스 가능 수준으로 나아가기 위해서 투명성은 반드시 필요하다.
도커의 매력은 컨테이너를 중심으로 만들어진 생태계와 이들 생태계를 구성하는 도구를 적용하는 패턴에 있다.

컨테이너 기술 초기 모니터링은 골치아팠다.
운영 환경에 투입된 앱 상태 파악이 너무 어려웠다.
시행착오를 겪으며 현대 앱에서는 신뢰성 있는 모니터링이 등장했다.

도커 엔진은 외부로 측정 값을 노출시키도록 설정한다.
이를 통해 컨테이너, 호스트에 대한 인프라 정보를 얻을 수 있다.

컨테이너에서 실행 중인 애플리케이션은 생성한 측정 값을 노출하도록 엔드포인트를 만든다.
측정 값은 런타임 수준의 성능 정보와 앱 내부 상황에 대한 사용자 정의 측정 값이 있다.

도커 엔진은 애플리케이션을 지속적으로 풀링하여 측정 값을 얻는다.

프로메테우스는 도커 엔진 및 앱 컨테이너로부터 측정 값을 수집하도록 설정한다.
컨테이너 수나 도커 서버가 변경돼도 문제 없이 수집 가능하다.

그라파나는 프로메테우스의 측정 값을 토대로 핵심 값을 정리해서 대시보드를 구성하고 설정한다.
각 그래프마다 프로메테우스에 PromQL 쿼리로 질의한 결과다.

## 9.6 연습 문제
- p.274 참고
- docker rm -f $(docker ps | awk '{print $1}')
  - 현재 실행중 컨테이너가 모두 삭제

# 10장 도커 컴포즈를 이용한 여러 환경 구성
이식성은 도커의 가장 핵심이다.

## 10.1 도커 컴포즈로 여러 개의 애플리케이션 배포하기
도커 컴포즈는 여러 개의 컨테이너로 구성된 앱을 단일 도커 엔진 호스트에서 실행하기 위한 도구다.
개발 환경 또는 테스트 환경에서 주로 쓰이며, 앱의 버전을 달리해 서로 다른 환경에서 구동해야 할 때도 유용하다.
무턱대고 여러 컨테이너를 같은 포트를 써서 사용하면 안 된다.
무턱대고 여러 컨테이너가 공유 자원으로써 데이터를 쓰게 하는 것도 안 좋다.

실습) p.275 참고
- cd ./ch10/exercises
- docker-compose -f ./numbers/docker-compose.yml up -d
- docker-compose -f ./todo-list/docker-compose.yml up -d
- docker-compose -f ./todo-list/docker-compose.yml up -d

무작위 숫자 앱과 todo 앱 두 개 실행
todo 앱 두 번쨰를 실행하면 컨테이너가 생성되지 않는다.
이미 앱 컨테이너가 구동중인 것을 확인하고 실행하지 않는다.

도커 컴포즈는 도커 리소스가 어떤 앱의 일부인지 판단하기 위해 '프로젝트'라는 개념을 사용한다.
도커 컴포즈 파일이 들어있는 디렉터리명인데, 프로젝트명을 리소스 이름 접두사로 붙이고, 컨테이너 이름에는 번호를 접미사로 붙인다.
디렉토리가 한글인 경우 컨테이너가 실행되지 않는 경우가 있는데, 접두사로써 잘못됐기 때문이다. (영어 쓰기)

따라서 같은 도커 컴포즈 파일로 두 번 실행해서 두 개의 컨테이너를 실행할 수 없다.
같은 디렉토리, 컨테이너명이 겹치기 때문에, 컴포즈 파일 기술 조건을 이미 만족하여 실행하지 않는다.

프로젝트 이름을 변경하는 방식으로 앱을 여러 개 구동시킬 수 있다.
실습) p.278 참고
- docker-compose -f ./todo-list/docker-compose.yml -p todo-test up -d
  - -p를 통해 새로 프로젝트 이름을 지정하면, 기존 실행되던 컨테이너와 별개로 취급된다.
- docker container ls
- docker container port todo-test_todo_web_1 80
  - todo_web은 무작위 포트를 개방하므로, 새 컨테이너 접근을 위해 개방 포트를 따로 알아내야 한다.

그러나 무작위로 정해진 포트를 일일이 찾아야 하는 것은 바람직하지 않다.
컴포즈 파일을 복사해 필요 부분만 수정하는 방법도 가능하지만,
도커 컴포즈는 설정을 오버라이드하는 좋은 기능이 있다.

## 10.2 도커 컴포즈의 오버라이드 파일
하나의 앱을 여러 설정으로 실행하고자 할 때, 도커 컴포즈 파일을 여러 개 두는 방법을 쓰는데, 
이는 유지 보수 측면에서 바람직하지 않다.
컴포즈 파일의 내용은 90% 이상 중복이니, 수정 또는 누락시 환경 차이 문제가 생긴다.

따라서 오버라이드를 통해 해결해야 한다.
도커 컴포즈는 여러 파일을 합쳐 컴포즈 파일을 구성한다.
나중에 지정된 파일 내용 또는 이전 파일 내용을 오버라이드 한다.

기본적인 앱 구조, 모든 환경의 공통 속성이 정의된 컴포즈 파일이 있고,
환경 별로 작성된 오버라이드 컴포즈 파일에 특정 환경의 속성을 정의한다.
따라서 환경 별 오버라이드 파일은 중복되지 않고 수정 또는 누락시 문제가 줄어든다.

- 공통 도커 컴포즈 파일
  - 서비스
- 개발 도커 컴포즈 파일
  - 서비스
  - 네트워크
- 테스트 도커 컴포즈 파일
  - 서비스
  - 네트워크
  - 볼륨

공통 도커 컴포즈 파일은 환경 별 도커 컴포즈 파일을 오버라이드 파일로 지정해 합쳐서 사용하면 된다.
중복을 줄이고 유지 보수성이 개선된다.
```yaml
# 공통 도커 컴포즈 파일
services:
  todo-web:
    image: diamol/ch06-todo-list
    ports:
      - 80
    environment:
      - Database:Provider=Sqlite
    networks:
      - app-net
  
# 오버라이드 도커 컴포즈 파일
services:
  todo-web:
    image: diamol/ch06-todo-list:v2
```
- 오버라이드 파일에서 변경할 항목만 기술한다. 컴포즈 파일의 속성 형태를 그대로 유지해야 한다.
- 도커 컴포즈는 하나 이상의 파일이 인자로 지정 됐을 때 파일을 병합한다.
  - config 부명령을 통해 입력 파일을 검증하여 유효한 경우만 최종 출력을 한다.

실습) p.284 참고
- docker-compose -f ./todo-list/docker-compose.yml -f ./todo-list/docker-compose-v2.yml config
  - 앱을 실행하진 않고, 병합된 컴포즈 파일을 미리 체크 가능하다.

오버라이드 파일 병합 순서는 인자로 받은 순서다.
즉 먼저 받은 파일의 속성을 오버라이드 하게 된다.
따라서 오버라이드 순서도 중요하다.

```yaml
services:
  numbers-api:
    ports:
      - "8087:80"
    healthcheck:
      disable: true
      
  numbers-web:
    entrypoint:
      - dotnet
      - Numbers.Web.dll
    ports:
      - "8088:80"
        
  networks:
    app-net:
      name: numbers-dev
```

실습) p.287 참고
- docker container rm -f $(docker container ls -aq)
- docker-compose -f ./numbers/docker-compose.yml -f ./numbers/docker-compose-dev.yml -p numbers-dev up -d
- docker-compose -f ./numbers/docker-compose.yml -f ./numbers/docker-compose-test.yml -p numbers-test up -d
- docker-compose -f ./numbers/docker-compose.yml -f ./numbers/docker-compose-uat.yml -p numbers-uat up -d

앱 세개가 실행되게 되고, 각각 별도 도커 네트워크를 사용하므로 독립적이다.
도메인 네임으로 IP 주소를 조회해 컨테이너에 접근하려면,
같은 도커 네트워크에 접속된 컨테이너여야 한다.

도커 컴포즈는 클라이언트에서 동작하는 도구다
일반적 상황에서 docker-compose down을 통해 컨테이너와 네트워크 제거를 하지만,
프로젝트 이름을 기본 값에서 변경했다면 병합된 파일들을 모두 지정해줘야 한다.
- docker-compose down
- docker-compose -f ./numbers/docker-compose.yml -f ./numbers/docker-compose-test.yml down
- docker-compose -f ./numbers/docker-compose.yml -f ./numbers/docker-compose-test.yml -p numbers-test down

이러한 이유로 도커 컴포즈 사용시 주의가 필요하다.
이와는 별개로 운영 외 환경에서 가장 유용하다.
오버라읻를 통해 재사용을 활용해 중복 제거를 할 수 있지만,
오버라이드 관리에 드는 오버헤드도 발생한다.
따라서 앱 배포 및 폐기 스크립트의 작성과 자동화를 익혀둬야 한다.

## 10.3 환경 변수와 비밀 값을 이용해 설정 주입하기
환경 변수와 설정 파일을 모두 다루기 위해 도커 컴포즈의 세부적인 동작을 알아보자.
환경에 따라 세 가지 설정 값을 변경해보자.
1. 로깅: 환경 별 로그 수준을 다르게 한다.
2. 데이터베이스 프로바이더: 별도 디비 컨테이너 지정
3. 데이터베이스 커넥션 문자열: 별도 디비 지정시 접속 정보 지정

```yaml
services:
  todo-web:
    image: diamol/ch06-todo-list
    secrets:
      - source: todo-db-connection
        target: /app/config/secrets.json
```
비밀 값은 도커 컴포즈, 도커 스웜, 쿠버네티스에서 모두 지원 가능하다.
설정 값 주입에 매우 유용하다.

컴포즈에서 비밀 값의 원본 위치와 대상 위치 모두 지정 가능하다.
비밀 값을 todo-db-connection에서 읽어오도록 지정했는데,
컴포즈 파일에 이 이름으로 정의 돼 있어야 한다.
그리고 이 값은 컨테이너 안 /app/config/secrets.json에 파일로 전달된다.
이 경로는 애플리케이션 설정 파일 찾는 경로이기도 하다.

```yaml
# 개발 환경 오버라이드 컴포즈 파일 - todo-db-connection 정의
services:
  todo-web:
    ports:
      - 8089:80
    environment:
      - Database:Provider=Sqlite
    env_file:
      - ./config/logging.debug.env

secrets:
  todo-db-connection:
    file: ./config/empty.json
```
세 가지 프로퍼티가 정의됐다.
셋 중 원하는 것을 골라 적용해도 되지만, 각각 장점이 있다.
**1. environment**
컨테이너 안에서만 사용되는 환경변수다.
해당 앱이 파일 데이터베이스인 SQLite를 사용한다.
설정 값을 전달하는 가장 간단한 방법이다.

**2. env_file**
텍스트 파일의 경로를 값으로 받는다.
이 파일에 정의된 환경 변수가 컨테이너에 적용되고,
여러 번 정의하지 않아도 여러 컴포넌트에 공유해 사용 가능하다.

**3. secrets**
최상위 프로퍼티로, todo-db-connection의 실제 값 혹은 경로가 정의된다.
예제상 빈 json파일을 넣었다.

실습) p.295 참고
- docker container rm -f $(docker ps | awk '{print $1}')
- docker-compose -f ./todo-list-configured/docker-compose.yml -f ./todo-list-configured/docker-compose-dev.yml -p todo-dev up -d
- curl http://localhost:8089/list
- docker container logs --tail 4 todo-dev_todo-web_1

도커 컴포즈는 앱 한 개 마다 도커 네트워크 하나씩 사용한다.
컴포즈 파일에 정의된 네트워크가 없어도 기본 네트워크에 컨테이너를 연결한다.

예제에서는 개발 환경에서 비밀 값 환경 변수로 설정 값 주입하고,
비밀 환경 변수는 컴포즈 파일의 지정 경로에 설정 파일로 읽어오는 방식을 사용했다.

테스트 환경에서 컴포즈가 제공하는 다른 방식으로 설정 값을 주입해보자.
호스트 컴퓨터의 환경 변수 값을 컨테이너에 전달하는 방법이다.

```yaml
services:
  todo-web:
    ports:
      - "${TODO_WEB_PORT}:80"
    environment:
      - Database:Provider=Postgres
    env_file:
      - ./config/logging.information.env
    networks:
      - app-net
```
- ${} 안에 적힌 이름의 환경 변수 값으로 치환된다.
- 컴포즈로 앱을 실행할 때 대상 디렉터리에 .env 파일 발견시 환경 파일로 간주, 앱 실행 전 먼저 적용한다.

실습) P.297 참고
- cd ./todo-list-configured
- docker-compose up -d

environment 프로퍼티를 사용해 환경 변수 지정하면 간단하고 컴포즈 파일 가독성이 좋아진다.
그러나 평문 텍스트로 작성하기에 민감한 정보는 사용하지 않는 것이 좋다.

비밀 값에 설정 값을 지정하면, 모든 컨테이너 런타임에 적용 가능하고, 민감 정보가 유출될 우려도 없다.
즉 유연성 면에서 가장 뛰어나다.
비밀 값을 실제 로컬 파일 시스템에 저장 할 수 있고, 도커 스웜이나 쿠버네티스 클러스터에 저장할 수도 있다.

env_file을 통해 설정 파일을 지정하는 방법은 서비스 간 공유가 많은 경우 유용하다.

환경 파일 .env는 다방면으로 기본 설정 지정시 유용하다.

## 10.4 확장 필드로 중복 제거하기
어떤 상황이든 적합한 도커 컴포즈 설정법이 있을 것 같이 느껴진다.
그러나 비교적 단순하기 때문에 금세 한계에 부딪힌다.

가장 흔한 경우는 서비스 간 많은 설정을 공유하는 컴포즈 파일의 덩치가 점점 커진다.
따라서 도커 컴포즈의 기능 확장 필드를 활용해야 한다.
확장 필드는 yaml 여러 블록을 한 곳에 정의한다.
이 블록을 재사용하는 효과를 얻을 수 있다.
강력한 기능 중 하나지만, 널리 쓰이진 않는다.

```yaml
x-labels: & logging
  logging:
    option:
      max-size: '100m'
      max-file: '10'
x-labels: & labels
  app-name: image-gallery
```
- logging과 labels 두 개의 확장 필드가 있다.
- 블록은 관습적으로 앞에 x를 붙인다.

```yaml
services:
  iotd:
    ports:
      - "8080:80"
    <<: *logging
    labels:
      <<: *lables
      public: api
```
- 확장 필드 재사용시 <<:*필드명 사용

실습) p.302 참고
- cd ./ch10/exercises/image-gallery
- docker-compose -f ./docker-compose.yml -f ./docker-compose-prod.yml config

도커 컴포즈 확장 필드는 통해 컴포즈 파일을 효율적으로 관리하는 방법 중 하나다.
하지만 확장 필드에도 여러 컴포즈 파일에 한 번에 적용 할 수 없다는 한계가 있다.
즉, 오버라이드 컴포즈 파일에는 사용 할 수 없다.
yaml의 한계지만, 잘 알아둬야 한다.

## 10.5 도커를 이용한 설정 워크플로 이해하기
환경마다 차이가 존재한다.
도커 컴포즈를 통해 환경 간 차이를 소스 코드 형상 관리를 통해 다룰 수 있다.

도커 컴포즈를 통한 환경 별 정의 방법 세 가지
1. 애플리케이션 구성 요소의 조합
2. 컨테이너 설정
3. 애플리케이션 설정

**애플리케이션 구성 요소의 조합**
모니터링, 개발 환경, 개발 환경간 설정파일

**컨테이너 설정**
유연성 있는 설정, 충돌 포트 관리, 볼륨, 오버라이드 설정 파일 등 요구 사항 만족시키며 단일 서버에 여러 개 앱 실행 가능


**애플리케이션 설정**
환경 별로 컨테이너 내부 동작이 달라야 하는 경우가 있다.
로그 수준, 캐시 용량, 특정 기능 온오프, 비밀 값 등

개발 환경은 로컬 디비, 로그 수준을 상세하게 남기고,
테스트 환경은 별도 디비 컨테이너로 지정, 별개 도커 네트워크 접속, 공개 포트도 다르다.
따라서 두 환경을 같은 서버에 실행시켜도 문제 없다.

이 설정 워크플로는 다음과 같다.
1. 모든 환경은 같은 이미지 사용
2. 빌드 - 자동화 테스트 - 특정 태그 컨테이너 이미지 생성
3. 해당 이미지를 컴포즈 파일에 포함된 설정 값으로 빌드, 검증, 테스트 환경에 배포
4. 모두 통과시 최종적으로 도커 스웜 또는 쿠버네티스 배포 매니페스트로 운영 환경에 이미지 배포

## 10.6 연습 문제
- p.307 참고


```yaml
# docker-compose.yml
version: '3.7'

services:
  todo-web:
    image: diamol/ch06-todo-list
    secrets:
      - source: todo-db-connection
        target: /app/config/secrets.json
```

```yaml
# docker-compose-dev.yml
version: '3.7'

services:
  todo-web:
    image: diamol/ch06-todo-list:v2
    ports:
      - "8089:80"
    environment:
      - Database:Provider=Sqlite
    env_file:
      - ./config/logging.debug.env

secrets:
  todo-db-connection:
    file: ./config/db-connection.json
```
- docker-compose -f ./docker-compose.yml -f ./docker-compose-dev.yml up -d

```yaml
# docker-compose-test.yml
version: '3.7'

services:
  todo-web:
    ports:
      - "8080:80"
    environment:
      - Database:Provider=Postgres
    networks:
      - app-net
  todo-db:
    image: diamol/postgres:11.5
    environment:
      - PGDATA:/data
    ports:
      - "5432:5432"
    volumes:
      - todo-v:/var/lib/mysql
    networks:
      - app-net

secrets:
  todo-db-connection:
    file: ./config/db-post-connection.json

volumes:
  todo-v:
    external:
      name: test-v

networks:
  app-net:
    external:
      name: nat
```
- docker-compose -f ./docker-compose.yml -f ./docker-compose-test.yml -p todo-test up -d

# 11장 도커와 도커 컴포즈를 이용한 애플리케이션 빌드 및 테스트
이식성과 더불어 자동화는 도커의 핵심이다.

패키징 절차를 도커 파일로 작성하여 애플리케이션 패키징을 도커 명령 하나로 자동화했다.
이번 장을 통해 도커를 이용한 지속적인 통합(Continuous Integration, CI)에 대해 배운다.

CI는 정기적으로 반복되고, 앱을 빌드하고 일련의 테스트를 수행하는 절차다.
CI 작업의 성공은 앱이 정상이고 패키징이 끝나 릴리스 후보로 배포될 준비가 된 상태라는 뜻이다.

도커를 이용한 CI 작업 간소화는 개발자들이 개발에 집중할 수 있도록 돕는다.

## 11.1 도커를 이용한 지속적 통합 절차
CI 절차는 코드로부터 시작하는 파이프라인이다.
CI 서버는 개발 환경마다 다른 모든 파이프라인을 다뤄야 해서 관리의 어려움을 겪는다.

도커는 CI 절차의 일관성을 유지해준다.
즉 똑같은 단계를 거쳐 똑같은 유형의 결과물로 생성해준다.

도커 CI 절차가 시작되면 빌드 및 테스트, 패키징, 배포를 위해 레지스트리에 푸시까지 끝난 이미지를 빌드한다.
도커화된 CI 절차에서 모든 일은 컨테이너 안에서 진행된다.

도커 CI 절차를 위해 필요한 것은 다음과 같다.
1. 중앙 집권적인 형상 관리 시스템
2. 이미지 저장을 위한 도커 레지스트리
3. CI 수행을 위한 자동화 서버
4. 인프라스트럭처적인 요소 등

모두 도커를 지원하기에 선택지가 많다.
깃헙, 애저 데브옵스, 도커 허브 조합으로 갈 수도 있고,
깃랩 한 개로 모든 역할을 수행할 수도 있다.

## 11.2 도커를 이용한 빌드 인프라스트럭처 구축하기
도커를 이용한 빌드 시스템은 배워둘 가치가 있다.
보안, 성능 등 이상적인 해결책이 되기도 한다.
인터넷 회선이 다운된 상황을 위한 대비책으로 비상 수단을 갖추는 것도 나쁘지 않다.

도커 CI를 위해 필요한 세 가지 컴포넌트는 오픈 소스를 통해 쉽게 컨테이너로 실행 가능하다.
1. 형상 관리 기능 - Gogs
2. 이미지 배포 - 오픈 소스 도커 레지스트리
3. 자동화 서버 - 젠킨스
- 모두 명령 한 번이면 설치 가능하다.

실습) p.311 참고
- cd ./ch11/exercises/infrastructure
- docker-compose -f docker-compose.yml -f docker-compose-linux.yml up -d
  - 기본 도커 레지스트리가 이미 5000 포트를 사용 중이라 예제랑 다르게 호스트는 5001로 지정함
- echo $'\n127.0.0.1 regstry.local' |sudo tee -a /etc/hosts
- docker container ls

실습) p.317 참고
- git remote add local http://localhost:3000/diamol/diamol.git
- git push local

실습) p.319 참고

도커 CLI는 기본적으로 로컬 컴에서 실행중인 도커 API에 접속 시도한다.
따라서 컨테이너에서 다른 컨테이너를 찾아달라고 요청하는 등의 행위가 가능해진다.
하지만 반대로 보안 문제가 생길 수 있다.

```yaml
# 젠킨스에 포함된 도커 CLI를 도커 엔진과 연결하기
# docker-compose.yml
services:
  jenkins:
    image: diamol/jenkins
    ports:
      - "8080:8080"
    networks:
      - infrastructure
```

```yaml
# docker-compose-linux.yml
services:
  jenkins:
    volumes:
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
```
- CI 인프라스트럭처는 이 설정이 전부다.

## 11.3 도커 컴포즈를 이용한 빌드 설정
```yaml
# docker-compose.yml
services:
  numbers-api:
    image: ${REGISTRY:-docker.io}/diamol/ch11-numbers-api:v3-build-${BUILD_NUMBER:-local}
    networks:
      - app-net
  numbers-web:
    image: ${REGISTRY:-docker.io}/diamol/ch11-numbers-web:v3-build-${BUILD_NUMBER:-local}
    environment:
      - RngApi__Url=http://numbers-api/rng
    networks:
      - app-net
```
- 환경 변수 중 기본 값을 의미하는 :- 문법이 사용됐다.
  - ${REGISTRY:-docker.io}
    - REGISTRY 환경 변수 값이 존재하지 않다며 기본 값으로 docker.io를 사용한다.

실습) p.326 참고
- cd ./ch11/exercises
- docker-compose -f docker-compose.yml -f docker-compose-build.yml build
- docker image inspect -f '{{.Config.Labels}}' diamol/ch11-numbers-api:v3-build-local

Label 인스트럭션은 Dockerfile 스크립트에 정의된 키-값 쌍을 빌드되는 이미지에 적용한다.
ARG 인스트럭션은 이미지 빌드 시점에만 유효하다는 점을 제외하면 EVN와 동일하다.

- services
  - image-api
    - build
      - context: numbers
      - dockerfile: aaa/Dockerfile

context: 도커가 빌드 중 사용할 작업 디렉토리 경로, 보통은 현재 디렉토리 (.)를 사용
dockerfile: Dockerfile 스크립트 경로, context 지정 경로를 기준으로 한다.
args: 빌드시 전달 인자

실습) p.329 참고
- cd ch11/exercises/numbers
- docker image build -f numbers-api/Dockerfile.v4 --build-arg BUILD_TAG=ch11 -t numbers-api .
- docker image inspect -f '{{.Config.Labels}}' numbers-api

## 11.4 도커 외의 의존 모듈이 불필요한 CI 작업 만들기

## 11.5 CI 파이프라인에 관계된 컨테이너

## 11.6 연습문제


















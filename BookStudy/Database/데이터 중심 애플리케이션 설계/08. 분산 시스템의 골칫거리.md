분산 시스템을 다루는 것은 관리가 더 어려울 수도 있고, 새롭고 흥미있는 방법이 많기도 하다.
분산 시스템으로 인한 문제점을 확인해보자.

시스템의 문제가 생기더라도 제 역할을 해내는 시스템을 구축해야 한다.
(내결함성? 고가용성?)
분산 시스템에서 이런 보장을 제공하는 알고리즘 몇 가지 예를 살펴보자.

분산 시스템에서 발생할 수 있는 문제는 많다.
1. 네트워크 관련 문제
2. 시계 및 타이밍 문제 (의존성 관련?)

이 문제들을 한 번에 파악할 순 없다.
따라서 분산 시스템의 상태에 대해 생각하는 방법과 무슨 일이 일어났는지 추론 하는 방법을 알아야 한다.

**결함과 부분 장애**
하나의 컴퓨터에서 프로그램을 작성할 때, 보통 상당히 예측 가능한 방식으로 동작한다.
쉽게 말해 되거나, 안되거나 둘 중 하나다.

단일 컴퓨터에서 실행되는 SW는 HW 문제 여부 영향에 따라 동작을 예측할 수 있다.
불분명하지 않고, 이상적인 시스템 모델을 보여주기도 한다.
CPU는 항상 같을 일을 하고, 메모리나 디스크 데이터도 온전히 저장되어 오염 가능성이 적다.

네트워크로 연결된 여러 컴퓨터에서 실행되는 SW는 근본적으로 다른 상황이다.
1. 데이터 센터 발생한 네트워크 분단
2. PDU(power distribution unit) 장애
3. 스위치 장애
4. 전체 랙에서 주기적 전원 사고
5. 전체 DC 백본 장애
6. 전체 DC 전원 장애
7. 외부 요인으로 인한 물리적 장비 장애

분산 시스템은 어떤 부분은 잘 동작하게 해주지만 예측할 수 없는 방식으로 고장나기도 한다.
이러한 부분 장애(partial failure)는 비결정적이라서 어렵다.
성공, 실패 또는 메시지 전송 시간도 모두 비결정적이다.
비결정성과 부분 장애는 분산 시스템을 다루기 어렵게 한다.

**클라우드 컴퓨팅과 슈퍼 컴퓨팅**
대규모 컴퓨팅 시스템 구축 방법에 대한 몇 가지 철학
- 대규모 컴퓨팅 끝에는 고성능 컴퓨팅 분야가 있다. 수천 개의 CPU를 가지고, 계산 비용이 매우 높은 과학 계산 작업에 쓰인다 (?)
- 클라우드 컴퓨팅이 있다, IDC, IP 네트웤, .... (?)
- 전통적 기업형 DC는 대규모 컴퓨팅, 클라우드 컴퓨팅 중간 지점에 있다.

철학에 따라 결함 처리 방법이 다르다.
슈퍼 컴은 시스템 어느 부분 장애 발생시 전체가 뻗는다.

분산 시스템이 잘 동작하려면 부분 장애 가능성을 받아들이고,
SW 내결함성 메커니즘을 추가해야 한다.
즉 신뢰성 없는 것을 신뢰성 있게 만들어야 한다.
적은 노드로 구성된 시스템이라도 부분 장애를 고려하는 것은 중요하다.
결함 처리는 소프트웨어 설계의 일부여야 하고, 결함 발생시 SW 동작을 예측하고 고려해야 한다.

**신뢰성 없는 네트워크**
책에서 다루는 분산 시스템은 비공유 시스템이다.
각 장비가 네트워크로 연결 되어 통신한다.
각 장비는 메모리와 디스크를 갖고, 다른 장비의 메모리와 디스크에 접근하지 못한다.

비공유 시스템 구축은 유일한 방법은 아니지만, 인터넷 서비스 구축의 주된 방법이 됐다.
HW 장비가 많이 필요하지 않고, 상대적 비용 절감과 지리적으로 분산된 IDC에 중복 배치를 통해 신뢰성을 확보한다.

인터넷과 데이터센터 내부 네트워크 대부분은 비동기 패킷 네트워크다.
따라서 요청과 응답 사이에 문제 발생 가능성이 있다.
1. 요청 손실 가능성
2. 요청이 큐에서 대기하다가 늦은 전송 가능성
3. 원격 노드 장애 가능성
4. 원격 노드 일시 응답 정지
5. 원격 노드가 요청 처리를 했지만 응답 손실 가능성
6. 원격 노드가 요청 처리를 했지만 응답 지연 가능성

요청, 응답 손실이 됐을 때 이유를 아는 것이 매우 어렵고 불가능하다.
이러한 문제를 다루는 흔한 방법은 타임아웃이다.
따라서 요청을 포기하더라도 이후에 메시지를 수신할 수 있다.

**현실의 네트워크 결함**
네트워크 결함은 피할 수 없다.
EC2 등의 공개 클라우드 서비스는 일시적 네트워크 결함이 자주 발생한다.
AWS 외에도 그 어떤 DC도 네트워크 문제를 피할 수 없다.

네트워크 결함의 오류 처리가 되지 않거나 테스트 되지 않는다면 큰일난다.
클러스터가 교착 상태에 빠져 네트워크가 복구되더라도 영구적으로 요청 처리 불가는ㅇ 할 수 있고,
모든 데이터를 지워버릴 수도 있다.
예측하지 못한 상황에 놓이면 제멋대로 동작될 수 있다.
이용자에게 오류를 전달하는 것도 방법이다.

**결함 감지**
시스템은 결함 있는 노드를 자동으로 감지할 수 있어야 한다.
로드밸런서는 죽은 노드로 요청을 그만 보내야 하고,
단일 리더 복제 사용시 리더 장애시 팔로워를 리더로 승격해야 한다.

네트워크의 불확실성으로 노드의 동작 여부를 구별하기 어렵다.
특정 환경에선 미동작을 명시적으로 알려주는 피드백을 받을 수 있다.

**타임아웃과 기약 없는 지연**
결함 감지의 방법으로 타임아웃을 사용한다면, 타임아웃을 얼마로 설정해야 할까?
답은 없다.

결함이 아닌데도 결함으로 판단 할 수도 있고, 결함인데도 불구하고 늦게 발견될 수도 있기 때문이다.
이용자의 서비스에 지장을 준다.

죽은 노드의 책무나 역할을 다른 노드로 전달 할 때 네트워크에 추가적인 부하를 준다.
따라서 결함을 제대로 인지 못하여 결함이라고 착각하게 해선 안 된다.

비동기 네트워크는 기약 없는 지연이 있고, 서버 구현은 요청 처리 시간을 보장 할 수 없다.

**네트워크 혼잡과 큐 대기**
- 여러 다른 노드를 동시에 같은 목적지로 패킷을 보낼 때, 패킷을 큐에 넣고 한 번에 하나씩 넘겨야 한다.
- 모든 CPU 코어가 바쁘다면, 요청은 운영체제가 큐에 넣어둔다. 장비에 따라 대기 시간은 제각각이다.

고정된 타임아웃을 설정하는 대신 시스템이 지속적으로 응답 시간과 변동성을 지터(jitter)를 체크하고, 타임 아웃을 자동 조절 할 수 있다.
TCP 재전송 타임아웃도 비슷하게 동작한다.

**동기 네트워크 vs 비동기 네트워크**
패킷 전송 지연 시간 최대치 고정, 패킷 유실 가능성이 없는 네트워크라면 분산 시스템은 훨씬 단순해진다.

HW 수준에서 해당 문제를 해결하고 네트워크 신뢰성 확보를 할 수 없을까?
이 질문에 답하기 위해선 데이터 센터 네트워크를 전통적인 고정 회선 전화 네트워크와 비교해보면 흥미롭다.
전화 네트워크는 극단적 신뢰성을 지닌다.
음성 프레임 지연, 통화 유실 가능성이 매우 적다.
전화 통화는 종단(end-to-end) 지연 시간이 낮아야 하고, 음성 샘플 전송 대역폭이 충분해야 한다.
컴퓨터 네트워크에서도 비슷한 신뢰성, 예측 가능성이 있따면 좋지 않을까?

전화 네트워크에서 톨화 시 '회선'이 만들어진다.
통화 대상 두 명 사이에 있는 전체 경로를 따라 고정되고 보장된 양의 대역폭이 할당된다.
회선은 통화가 끝날 때 까지 유지된다.
예를 들어 ISDN 네트워크(?)는 초당 4,000 프레임의 고정된 비율로 실행된다.
따라서 각 프레임 내에(양방향으로) 16비트의 공간을 할당한다.
그래서 통화하는 동안 양측은 250마이크로초마다 정확히 16비트의 오디오 데이터를 보낼 수 있도록 보장된다.

예시로 든 네트워크는 **동기식**이다. (? 전화라는 프로세스는 비동기 같은데, 전화 네트워크가 동기식이란건가?)
데이터가 여러 라우터를 거치더라도 큐 대기 문제를 겪지 않는다.
네트워크의 다음 홉(hop)에 통화당 16비트 공간이 이미 할당되어 있다.
큐 대기가 없으므로 네트워크 종단 지연 시간 최대치가 고정돼 있다.
이를 제한 있는 지연이라 한다.

**그냥 네트워크 지연을 예측 가능하게 만들 수 없을까?**
전화 네트워크의 회선은 TCP 연결과 매우 다르다는 점을 주목해야 한다.

회선은 생성 후 소멸 전 까지 다른 누구도 사용할 수 없는 고정된 양의 예약된 대역폭이다.
TCP 연결의 패킷은 가용한 네트워크 대역폭을 기회주의적으로 사용한다.
TCP에 가변 크기 데이터 블록을 보내면(이메일, 웹 페이지, ...) 가능하면 짧은 시간 안에 전송한다.
TCP 연결이 유휴 상태에 있는 동안 어떤 대역폭도 사용하지 않는다.

데이터센터 네트워크와 인터넷이 회선 교환 네트워크라면, 회선 구성시 왕복 시간 최대치 보장 가능하다.
그러나 이더넷과 IP는 큐 대기의 영향을 받는 패킷 교환 프로토콜이다.
따라서 네트워크에 기약 없는 지연이 있다. 이 프로토콜에는 회선 개념이 없다.

왜 데이터센터 네트워크와 인터넷은 패킷 교환을 사용할까?
바로 순간적으로 몰리는 트래픽에 최적화 됐기 때문이다.

회선은 통화하는 동안 보내는 초당 비트 개수가 상당히 고정돼 있는 음성과 영상 통화에 적합하다.
웹 페이지 요청, 메일 전송, 파일 전송은 특별한 대역폭 요구사항이 없고 단지 가능한 빨리 완료되기를 바란다.

회선을 통한 파일 전송을 하려면, 우선 대역폭 할당을 추정해야 한다.
추정치가 너무 낮거나 너무 높으면 안 된다.
반면 TCP는 가용한 네트워크 용량에 맞춰 데이터 전송률을 동적으로 조절한다.

**지연 시간과 자원 사용률**
고정 회선은 동시 통화를 10,000개 까지 전송할 수 있어도, 
선로를 쓰는 회선이 하나라면 9,999개는 모두 사용하지 않아도 전부 사용하는 것 처럼 고정된 양의 대역폭을 할당 받는다.

반대로 인터넷은 대역폭을 동적으로 공유한다.
패킷을 선로로 보내기 위해 치열하다. 
큐 대기가 생기는 단점이 있지만, 선로를 최대한 활용할 수 있는 장점이 있다.
선로는 고정 비용이다. 사용률이 높을 수록 개별 바이트 비용은 저렴하다.

CPU도 비슷하다.
각 CPU 코어를 여러 스레드 사이에서 동적으로 공유시 스레드는 다른 스레드가 실행되는 동안 OS 큐에서 대기한다.
따라서 스레드는 가변 길이 시간 동안 중단 될 수 있다.

자원이 정적으로 분할된다면, 환경에 따라 지연 시간 보장 가능하다.
그러나 사용률이 줄어드는 비용이 따른다.

네트워크에서 변동이 큰 지연은 단지 **비용과 이득**의 트레이드오프 결과일 뿐이다.

**신뢰성 없는 시계**
시계와 시간은 중요하다.
앱에서 시간은 특히 중요하다.
1. 요청이 타임아웃 됐나?
2. 응답 시간은 어떻게 되나?
3. 지난 5분 동안 평균 초당 몇 개 질의 처리했나?
4. 이용자가 서비스에서 보낸 시간은 얼마인가?
5. 미리 알림 이메일을 보내야 하나?
6. 캐시 항목의 만료 시간은?
7. 로그 파일에 남은 타임 스탬프는 무엇인가?

분산 시스템은 통신이 즉각적이지 않아서 시간을 다루기 까다롭다.
메시지는 네트워크를 거치고 다른 장비를 전달 시간이 소요된다.

각 장비는 개별 시간을 갖고 있다. 다른 장비와 시간이 다를 수도 있는데,
시간을 어느 정도 동기화 할 수 있다. 
가장 널리 쓰이는 메커니즘은 네트워크 시간 프로토콜이다.

**단조 시계 대 일 기준 시계**

현대 컴퓨터는 최소 두 종류의 시계를 갖는다.
1. 일 기준 시계
2. 단조 시계

**일 기준 시계**

**단조 시계**
타임아웃, 서비스 응답 시간 등 지속 시간을 재는데 적합하다.

**시계 동기화와 정확도**

**동기화된 시계에 의존하기**
시계는 함정이 있다.
하루는 정확히 86,400초가 아닐 수도 있다. 
시간이 거꾸로 가게 설정 됐거나 노드간 시간의 차이가 많이 날 수도 있다.

네트워크의 시간과 별개로 SW는 네트워크의 결함 가능성을 가정하에 설계해야 된다.
시계도 마찬가지로 잘못된 시계에 대비할 필요가 있다.

문제는 시계가 잘못됐음을 인지하기 쉽지 않다.
물리 장비 같은 경우 동작 여부에 따라 빨리 발견되지만, 
시계의 경우 시간이 점점 멀어져 가지만 잘 동작하는 것 처럼 보인다.

따라서 동기화된 시계가 필요한 SW 사용시 필수적으로 모든 장비 사이의 시계 차이를 모니터링 해야한다.

**이벤트 순서화용 타임스탬프**
여러 노드에 걸친 이벤트 순서를 정할 때,
두 클라이언트가 분산 데이터베이스에 쓰면 누가 먼저 쓰기 작업을 시작할까?

다중 리더 복제 상황에서 다른 노드 복제시 노드의 일 기준 시계에 따른 타임스탬프가 붙는다.
타임스탬프로 이벤트 순서를 올바르게 정할 순 없다.

이 충돌 해소충돌 해소 전략은 **최종 쓰기 승리(Last Write Wins)**라 불리며 다중 리더 복제, 카산드라, 라악 등
리더 없는 데이터베이스에 널리 사용된다.

- DB 쓰기 손실 가능성, 시간 차이로 인해 시간 차이 만큼 덮어 쓸 수 없다. -> 어떤 오류도 뜨지 않는다.
- 시간 내 연속 실행과 동시 쓰기 요청이 온 것을 구별 할 수 없다.

가장 "최근" 값을 유지하고, 다른 걸 버린다면 "최근"의 기준 시간이 다를 수 있따는 것을 아는 것이 중요하다.

**시계 읽기는 신뢰 구간이 있다.**

**전역 스냅숏용 동기화된 시계**

**프로세스 중단**
단일 장비에서 다중 스레드 코드 작성시 그 코드를 스레드 안전하게 만들 수 있는 좋은 도구가 있다.
1. 뮤텍스(mutext)
2. 세마포어(semaphore)
3. 원자적 카운터(atomic counter)
4. 잠금 없는(lock-free) 자료구조
5. 블로킹 큐(blocking queue)
6. 등등등

**응답 시간 보장**
OS에서 스레드와 프로세스는 기약 없는 시간동안 중단될 수 있다.
중단의 원인을 제거해야 한다.
물리적 물체를 제어하는 컴퓨터는 센서에 빠른 입력과 예측 가능한 응답을 해야 한다.
엄격한 실시간 시스템을 구축해야 한다.

실시간은 정말로 실시간인가?
임베디드 시스템, 웹 등 용어적 해석이 다르다.

**가비지 컬렉션의 영향을 제한하기**

**지식, 진실, 그리고 거짓말**

**진실은 다수결로 결정된다**

**리더와 잠금**
분산 시스템에서 어떤 노드가 리더였더라도, 그 노드는 아직 리더라고 스스로 판단하더라도,
이미 다른 리더가 선출되어 기존 노드는 강등됐을 수도 있다.

과반수 노드가 특정 노드가 죽었다고 선언해도, 특정 노드가 안 죽은것 마냥 계속 행동한다면 문제를 유발 할 수 있다.

**펜싱 토큰**
특정 노드가 과반수에 의해 죽었더라도, 안 죽은 것처럼 행위 할 때, 
시스템을 방해할 수 없도록 보장해야 한다.
단순한 기법으로 펜싱(fencing)이 있다.

**비잔틴 결함**

**약한 형태의 거짓말**

**알고리즘의 정확성**

**안전성과 활동성**

**시스템 모델을 현실 세계에 대응시키기**









